<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://oldcamel.run</id>
    <title>Old Camel</title>
    <updated>2021-09-08T03:34:31.587Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://oldcamel.run"/>
    <link rel="self" href="https://oldcamel.run/atom.xml"/>
    <subtitle>希望自己可以做喜欢的事，可以多去远方看看 
&lt;div&gt;&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=18611643&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;</subtitle>
    <logo>https://oldcamel.run/images/avatar.png</logo>
    <icon>https://oldcamel.run/favicon.ico</icon>
    <rights>All rights reserved 2021, Old Camel</rights>
    <entry>
        <title type="html"><![CDATA[Oauth2RedisTokenStore JSON序列化实现]]></title>
        <id>https://oldcamel.run/post/oauth2redistokenstore-json-xu-lie-hua-shi-xian/</id>
        <link href="https://oldcamel.run/post/oauth2redistokenstore-json-xu-lie-hua-shi-xian/">
        </link>
        <updated>2021-09-02T01:51:48.000Z</updated>
        <content type="html"><![CDATA[<h1 id="修改默认的java-jdk序列化方式为json格式-使用fastjson目的是为了兼容不同项目使用不同的spring-boot版本">修改默认的java jdk序列化方式为json格式。使用fastjson，目的是为了兼容不同项目使用不同的spring boot版本。</h1>
<h2 id="yunzaijsonredistokenstore-自定义tokenstore同时设置caffeine缓存">YunzaiJsonRedisTokenStore 自定义TokenStore，同时设置Caffeine缓存</h2>
<pre><code class="language-java">package com.yunzainfo.cloud.mars.autoconfigure;

import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import com.yunzainfo.cloud.mars.common.security.FastjsonRedisTokenStoreSerializationStrategy;
import org.springframework.data.redis.connection.RedisConnection;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.Cursor;
import org.springframework.data.redis.core.ScanOptions;
import org.springframework.security.oauth2.common.ExpiringOAuth2RefreshToken;
import org.springframework.security.oauth2.common.OAuth2AccessToken;
import org.springframework.security.oauth2.common.OAuth2RefreshToken;
import org.springframework.security.oauth2.provider.OAuth2Authentication;
import org.springframework.security.oauth2.provider.token.AuthenticationKeyGenerator;
import org.springframework.security.oauth2.provider.token.DefaultAuthenticationKeyGenerator;
import org.springframework.security.oauth2.provider.token.TokenStore;
import org.springframework.security.oauth2.provider.token.store.redis.RedisTokenStoreSerializationStrategy;
import org.springframework.util.ClassUtils;
import org.springframework.util.ReflectionUtils;

import java.lang.reflect.Method;
import java.util.*;
import java.util.concurrent.TimeUnit;
import java.util.function.Function;


public class YunzaiJsonRedisTokenStore implements TokenStore {
    private static final String ACCESS = &quot;access:&quot;;
    private static final String AUTH_TO_ACCESS = &quot;auth_to_access:&quot;;
    private static final String AUTH = &quot;auth:&quot;;
    private static final String REFRESH_AUTH = &quot;refresh_auth:&quot;;
    private static final String ACCESS_TO_REFRESH = &quot;access_to_refresh:&quot;;
    private static final String REFRESH = &quot;refresh:&quot;;
    private static final String REFRESH_TO_ACCESS = &quot;refresh_to_access:&quot;;
    private static final String CLIENT_ID_TO_ACCESS = &quot;client_id_to_access:&quot;;
    private static final String UNAME_TO_ACCESS = &quot;uname_to_access:&quot;;

    private static final boolean springDataRedis_2_0 = ClassUtils.isPresent(
            &quot;org.springframework.data.redis.connection.RedisStandaloneConfiguration&quot;,
            YunzaiJsonRedisTokenStore.class.getClassLoader());
    private final RedisConnectionFactory connectionFactory;
    private AuthenticationKeyGenerator authenticationKeyGenerator = new DefaultAuthenticationKeyGenerator();
    private RedisTokenStoreSerializationStrategy serializationStrategy = new FastjsonRedisTokenStoreSerializationStrategy();
    private String prefix = &quot;&quot;;
    private Method redisConnectionSet_2_0;
    private final static Cache&lt;Object, Object&gt; CACHE;
    static {
        CACHE = Caffeine.newBuilder()
                .expireAfterAccess(30, TimeUnit.MINUTES)
                .maximumSize(10000).build();
    }
    public YunzaiJsonRedisTokenStore(RedisConnectionFactory connectionFactory) {
        this.connectionFactory = connectionFactory;
        if (springDataRedis_2_0) {
            this.loadRedisConnectionMethods_2_0();
        }
    }

    public void setAuthenticationKeyGenerator(AuthenticationKeyGenerator authenticationKeyGenerator) {
        this.authenticationKeyGenerator = authenticationKeyGenerator;
    }

    public void setSerializationStrategy(RedisTokenStoreSerializationStrategy serializationStrategy) {
        this.serializationStrategy = serializationStrategy;
    }

    public void setPrefix(String prefix) {
        this.prefix = prefix;
    }

    private void loadRedisConnectionMethods_2_0() {
        this.redisConnectionSet_2_0 = ReflectionUtils.findMethod(
                RedisConnection.class, &quot;set&quot;, byte[].class, byte[].class);
    }

    private RedisConnection getConnection() {
        return connectionFactory.getConnection();
    }

    private byte[] serialize(Object object) {
        return serializationStrategy.serialize(object);
    }

    private byte[] serializeKey(String object) {
        return serialize(prefix + object);
    }

    private OAuth2AccessToken deserializeAccessToken(byte[] bytes) {
        return serializationStrategy.deserialize(bytes, OAuth2AccessToken.class);
    }

    private OAuth2Authentication deserializeAuthentication(byte[] bytes) {
        return serializationStrategy.deserialize(bytes, OAuth2Authentication.class);
    }

    private OAuth2RefreshToken deserializeRefreshToken(byte[] bytes) {
        return serializationStrategy.deserialize(bytes, OAuth2RefreshToken.class);
    }

    private byte[] serialize(String string) {
        return serializationStrategy.serialize(string);
    }

    private String deserializeString(byte[] bytes) {
        return serializationStrategy.deserializeString(bytes);
    }

    @Override
    public OAuth2AccessToken getAccessToken(OAuth2Authentication authentication) {
        String key = authenticationKeyGenerator.extractKey(authentication);
        String AccessToAccessKey=AUTH_TO_ACCESS + key;
        return (OAuth2AccessToken) loadCache(AccessToAccessKey, (k) -&gt; {
            byte[] serializedKey = serializeKey(k);
            byte[] bytes = null;
            RedisConnection conn = getConnection();
            try {
                bytes = conn.get(serializedKey);
            } finally {
                conn.close();
            }
            OAuth2AccessToken accessToken = deserializeAccessToken(bytes);
            if (accessToken != null) {
                OAuth2Authentication storedAuthentication = readAuthentication(accessToken.getValue());
                if ((storedAuthentication == null || !key.equals(authenticationKeyGenerator.extractKey(storedAuthentication)))) {
                    // Keep the stores consistent (maybe the same user is
                    // represented by this authentication but the details have
                    // changed)
                    storeAccessToken(accessToken, authentication);
                }
            }
            return accessToken;
        });
    }

    @Override
    public OAuth2Authentication readAuthentication(OAuth2AccessToken token) {
        return readAuthentication(token.getValue());
    }

    @Override
    public OAuth2Authentication readAuthentication(String token) {
        String key = AUTH + token;
        return (OAuth2Authentication) loadCache(key, (k) -&gt; {
            byte[] bytes = null;
            RedisConnection conn = getConnection();
            try {
                bytes = conn.get(serializeKey(k));
            } finally {
                conn.close();
            }
            OAuth2Authentication auth = deserializeAuthentication(bytes);
            return auth;
        });

    }

    @Override
    public OAuth2Authentication readAuthenticationForRefreshToken(OAuth2RefreshToken token) {
        return readAuthenticationForRefreshToken(token.getValue());
    }

    public OAuth2Authentication readAuthenticationForRefreshToken(String token) {
        String refreshAuthKey=REFRESH_AUTH + token;
        return (OAuth2Authentication) loadCache(refreshAuthKey, (k) -&gt; {
            RedisConnection conn = getConnection();
            try {
                byte[] bytes = conn.get(serializeKey(k));
                OAuth2Authentication auth = deserializeAuthentication(bytes);
                return auth;
            } finally {
                conn.close();
            }
        });

    }

    @Override
    public void storeAccessToken(OAuth2AccessToken token, OAuth2Authentication authentication) {
        byte[] serializedAccessToken = serialize(token);
        byte[] serializedAuth = serialize(authentication);
        byte[] accessKey = serializeKey(ACCESS + token.getValue());
        byte[] authKey = serializeKey(AUTH + token.getValue());
        byte[] authToAccessKey = serializeKey(AUTH_TO_ACCESS + authenticationKeyGenerator.extractKey(authentication));
        byte[] approvalKey = serializeKey(UNAME_TO_ACCESS + getApprovalKey(authentication));
        byte[] clientId = serializeKey(CLIENT_ID_TO_ACCESS + authentication.getOAuth2Request().getClientId());

        RedisConnection conn = getConnection();
        try {
            conn.openPipeline();
            if (springDataRedis_2_0) {
                try {
                    this.redisConnectionSet_2_0.invoke(conn, accessKey, serializedAccessToken);
                    this.redisConnectionSet_2_0.invoke(conn, authKey, serializedAuth);
                    this.redisConnectionSet_2_0.invoke(conn, authToAccessKey, serializedAccessToken);
                } catch (Exception ex) {
                    throw new RuntimeException(ex);
                }
            } else {
                conn.set(accessKey, serializedAccessToken);
                conn.set(authKey, serializedAuth);
                conn.set(authToAccessKey, serializedAccessToken);
            }
            if (!authentication.isClientOnly()) {
                conn.sAdd(approvalKey, serializedAccessToken);
            }
            conn.sAdd(clientId, serializedAccessToken);
            if (token.getExpiration() != null) {
                int seconds = token.getExpiresIn();
                conn.expire(accessKey, seconds);
                conn.expire(authKey, seconds);
                conn.expire(authToAccessKey, seconds);
                conn.expire(clientId, seconds);
                conn.expire(approvalKey, seconds);
            }
            OAuth2RefreshToken refreshToken = token.getRefreshToken();
            if (refreshToken != null &amp;&amp; refreshToken.getValue() != null) {
                byte[] refresh = serialize(token.getRefreshToken().getValue());
                byte[] auth = serialize(token.getValue());
                byte[] refreshToAccessKey = serializeKey(REFRESH_TO_ACCESS + token.getRefreshToken().getValue());
                byte[] accessToRefreshKey = serializeKey(ACCESS_TO_REFRESH + token.getValue());
                if (springDataRedis_2_0) {
                    try {
                        this.redisConnectionSet_2_0.invoke(conn, refreshToAccessKey, auth);
                        this.redisConnectionSet_2_0.invoke(conn, accessToRefreshKey, refresh);
                    } catch (Exception ex) {
                        throw new RuntimeException(ex);
                    }
                } else {
                    conn.set(refreshToAccessKey, auth);
                    conn.set(accessToRefreshKey, refresh);
                }
                if (refreshToken instanceof ExpiringOAuth2RefreshToken) {
                    ExpiringOAuth2RefreshToken expiringRefreshToken = (ExpiringOAuth2RefreshToken) refreshToken;
                    Date expiration = expiringRefreshToken.getExpiration();
                    if (expiration != null) {
                        int seconds = Long.valueOf((expiration.getTime() - System.currentTimeMillis()) / 1000L)
                                .intValue();
                        conn.expire(refreshToAccessKey, seconds);
                        conn.expire(accessToRefreshKey, seconds);
                    }
                }
                CACHE.put(deserializeString(refreshToAccessKey), token.getValue());
                CACHE.put(deserializeString(accessToRefreshKey), refreshToken.getValue());
            }
            CACHE.put(deserializeString(accessKey), token);
            CACHE.put(deserializeString(authKey), authentication);
            CACHE.put(deserializeString(authToAccessKey), token);
            conn.closePipeline();
        } finally {
            conn.close();
        }
    }

    private static String getApprovalKey(OAuth2Authentication authentication) {
        String userName = authentication.getUserAuthentication() == null ? &quot;&quot;
                : authentication.getUserAuthentication().getName();
        return getApprovalKey(authentication.getOAuth2Request().getClientId(), userName);
    }

    private static String getApprovalKey(String clientId, String userName) {
        return clientId + (userName == null ? &quot;&quot; : &quot;:&quot; + userName);
    }

    @Override
    public void removeAccessToken(OAuth2AccessToken accessToken) {
        removeAccessToken(accessToken.getValue());
    }

    @Override
    public OAuth2AccessToken readAccessToken(String tokenValue) {
        String accessTokenKey = ACCESS + tokenValue;
        return (OAuth2AccessToken) loadCache(accessTokenKey, (k) -&gt; {
            byte[] key = serializeKey(k);
            byte[] bytes = null;
            RedisConnection conn = getConnection();
            try {
                bytes = conn.get(key);
            } finally {
                conn.close();
            }
            OAuth2AccessToken accessToken = deserializeAccessToken(bytes);
            return accessToken;
        });
    }

    public void removeAccessToken(String tokenValue) {
        byte[] accessKey = serializeKey(ACCESS + tokenValue);
        byte[] authKey = serializeKey(AUTH + tokenValue);
        byte[] accessToRefreshKey = serializeKey(ACCESS_TO_REFRESH + tokenValue);
        RedisConnection conn = getConnection();
        try {
            conn.openPipeline();
            conn.get(accessKey);
            conn.get(authKey);
            conn.del(accessKey);
            conn.del(accessToRefreshKey);
            // Don't remove the refresh token - it's up to the caller to do that
            conn.del(authKey);
            List&lt;Object&gt; results = conn.closePipeline();
            byte[] access = (byte[]) results.get(0);
            byte[] auth = (byte[]) results.get(1);
            List&lt;String&gt; keys = new ArrayList&lt;&gt;(6);
            keys.add(deserializeString(accessKey));
            keys.add(deserializeString(authKey));
            keys.add(deserializeString(accessToRefreshKey));
            CACHE.invalidateAll(keys);
            OAuth2Authentication authentication = deserializeAuthentication(auth);
            if (authentication != null) {
                String key = authenticationKeyGenerator.extractKey(authentication);
                byte[] authToAccessKey = serializeKey(AUTH_TO_ACCESS + key);
                byte[] unameKey = serializeKey(UNAME_TO_ACCESS + getApprovalKey(authentication));
                byte[] clientId = serializeKey(CLIENT_ID_TO_ACCESS + authentication.getOAuth2Request().getClientId());
                conn.openPipeline();
                conn.del(authToAccessKey);
                conn.sRem(unameKey, access);
                conn.sRem(clientId, access);
                conn.del(serialize(ACCESS + key));
                conn.closePipeline();
                CACHE.invalidate(deserializeString(authToAccessKey));
                CACHE.invalidate(ACCESS + key);
            }
        } finally {
            conn.close();
        }
    }

    @Override
    public void storeRefreshToken(OAuth2RefreshToken refreshToken, OAuth2Authentication authentication) {
        byte[] refreshKey = serializeKey(REFRESH + refreshToken.getValue());
        byte[] refreshAuthKey = serializeKey(REFRESH_AUTH + refreshToken.getValue());
        byte[] serializedRefreshToken = serialize(refreshToken);
        RedisConnection conn = getConnection();
        try {
            conn.openPipeline();
            if (springDataRedis_2_0) {
                try {
                    this.redisConnectionSet_2_0.invoke(conn, refreshKey, serializedRefreshToken);
                    this.redisConnectionSet_2_0.invoke(conn, refreshAuthKey, serialize(authentication));
                } catch (Exception ex) {
                    throw new RuntimeException(ex);
                }
            } else {
                conn.set(refreshKey, serializedRefreshToken);
                conn.set(refreshAuthKey, serialize(authentication));
            }
            if (refreshToken instanceof ExpiringOAuth2RefreshToken) {
                ExpiringOAuth2RefreshToken expiringRefreshToken = (ExpiringOAuth2RefreshToken) refreshToken;
                Date expiration = expiringRefreshToken.getExpiration();
                if (expiration != null) {
                    int seconds = Long.valueOf((expiration.getTime() - System.currentTimeMillis()) / 1000L)
                            .intValue();
                    conn.expire(refreshKey, seconds);
                    conn.expire(refreshAuthKey, seconds);
                }
            }
            CACHE.put(deserializeString(refreshKey), refreshToken);
            CACHE.put(deserializeString(refreshAuthKey), authentication);
            conn.closePipeline();
        } finally {
            conn.close();
        }
    }

    @Override
    public OAuth2RefreshToken readRefreshToken(String tokenValue) {
        String refreshTokenKey=REFRESH + tokenValue;
        return (OAuth2RefreshToken) loadCache(refreshTokenKey, (k) -&gt; {
            byte[] key = serializeKey(k);
            byte[] bytes = null;
            RedisConnection conn = getConnection();
            try {
                bytes = conn.get(key);
            } finally {
                conn.close();
            }
            OAuth2RefreshToken refreshToken = deserializeRefreshToken(bytes);
            return refreshToken;
        });


    }

    @Override
    public void removeRefreshToken(OAuth2RefreshToken refreshToken) {
        removeRefreshToken(refreshToken.getValue());
    }

    public void removeRefreshToken(String tokenValue) {
        byte[] refreshKey = serializeKey(REFRESH + tokenValue);
        byte[] refreshAuthKey = serializeKey(REFRESH_AUTH + tokenValue);
        byte[] refresh2AccessKey = serializeKey(REFRESH_TO_ACCESS + tokenValue);
        byte[] access2RefreshKey = serializeKey(ACCESS_TO_REFRESH + tokenValue);
        RedisConnection conn = getConnection();
        try {
            conn.openPipeline();
            conn.del(refreshKey);
            conn.del(refreshAuthKey);
            conn.del(refresh2AccessKey);
            conn.del(access2RefreshKey);
            conn.closePipeline();
        } finally {
            conn.close();
        }
        List&lt;String&gt; keys = new ArrayList&lt;&gt;(7);
        keys.add(deserializeString(refreshKey));
        keys.add(deserializeString(refreshAuthKey));
        keys.add(deserializeString(refresh2AccessKey));
        keys.add(deserializeString(access2RefreshKey));
        CACHE.invalidateAll(keys);
    }

    private &lt;T&gt; Object loadCache(String key, Function&lt;String, ? extends T&gt; loadData) {
        try {
            Object value = CACHE.getIfPresent(key);
            if (value == null) {
                value = loadData.apply(key);
                if (value != null) {
                    CACHE.put(key, value);
                }
            }
            return value;
        } catch (Exception e) {
            throw new RuntimeException(&quot;YunzaiJsonRedisTokenStore.loadCache从缓存中加载数据发生错误&quot;, e);
        }
    }
    @Override
    public void removeAccessTokenUsingRefreshToken(OAuth2RefreshToken refreshToken) {
        removeAccessTokenUsingRefreshToken(refreshToken.getValue());
    }

    private void removeAccessTokenUsingRefreshToken(String refreshToken) {
        byte[] key = serializeKey(REFRESH_TO_ACCESS + refreshToken);
        List&lt;Object&gt; results = null;
        RedisConnection conn = getConnection();
        try {
            conn.openPipeline();
            conn.get(key);
            conn.del(key);
            results = conn.closePipeline();
        } finally {
            conn.close();
        }
        if (results == null) {
            return;
        }
        byte[] bytes = (byte[]) results.get(0);
        String accessToken = deserializeString(bytes);
        if (accessToken != null) {
            removeAccessToken(accessToken);
        }
        CACHE.invalidate(deserializeString(key));

    }

    private List&lt;byte[]&gt; getByteLists(byte[] approvalKey, RedisConnection conn) {
        List&lt;byte[]&gt; byteList;
        Long size = conn.sCard(approvalKey);
        byteList = new ArrayList&lt;byte[]&gt;(size.intValue());
        Cursor&lt;byte[]&gt; cursor = conn.sScan(approvalKey, ScanOptions.NONE);
        while(cursor.hasNext()) {
            byteList.add(cursor.next());
        }
        return byteList;
    }

    @Override
    public Collection&lt;OAuth2AccessToken&gt; findTokensByClientIdAndUserName(String clientId, String userName) {
        byte[] approvalKey = serializeKey(UNAME_TO_ACCESS + getApprovalKey(clientId, userName));
        List&lt;byte[]&gt; byteList = null;
        RedisConnection conn = getConnection();
        try {
            byteList = getByteLists(approvalKey, conn);
        } finally {
            conn.close();
        }
        if (byteList == null || byteList.size() == 0) {
            return Collections.&lt;OAuth2AccessToken&gt; emptySet();
        }
        List&lt;OAuth2AccessToken&gt; accessTokens = new ArrayList&lt;OAuth2AccessToken&gt;(byteList.size());
        for (byte[] bytes : byteList) {
            OAuth2AccessToken accessToken = deserializeAccessToken(bytes);
            accessTokens.add(accessToken);
        }
        return Collections.&lt;OAuth2AccessToken&gt; unmodifiableCollection(accessTokens);
    }

    @Override
    public Collection&lt;OAuth2AccessToken&gt; findTokensByClientId(String clientId) {
        byte[] key = serializeKey(CLIENT_ID_TO_ACCESS + clientId);
        List&lt;byte[]&gt; byteList = null;
        RedisConnection conn = getConnection();
        try {
            byteList = getByteLists(key, conn);
        } finally {
            conn.close();
        }
        if (byteList == null || byteList.size() == 0) {
            return Collections.&lt;OAuth2AccessToken&gt; emptySet();
        }
        List&lt;OAuth2AccessToken&gt; accessTokens = new ArrayList&lt;OAuth2AccessToken&gt;(byteList.size());
        for (byte[] bytes : byteList) {
            OAuth2AccessToken accessToken = deserializeAccessToken(bytes);
            accessTokens.add(accessToken);
        }
        return Collections.&lt;OAuth2AccessToken&gt; unmodifiableCollection(accessTokens);
    }


}

</code></pre>
<h2 id="fastjsonredistokenstoreserializationstrategy-json序列化认证授权信息">FastjsonRedisTokenStoreSerializationStrategy json序列化认证授权信息</h2>
<pre><code class="language-java">
import cn.hutool.core.util.ReflectUtil;
import com.alibaba.fastjson.JSON;
import com.alibaba.fastjson.parser.ParserConfig;
import com.alibaba.fastjson.serializer.SerializerFeature;
import com.alibaba.fastjson.util.IOUtils;
import com.alibaba.fastjson.util.TypeUtils;
import com.google.common.base.Preconditions;
import org.apache.commons.lang.SerializationException;
import org.springframework.security.oauth2.common.DefaultOAuth2RefreshToken;
import org.springframework.security.oauth2.provider.OAuth2Authentication;
import org.springframework.security.oauth2.provider.OAuth2Request;
import org.springframework.security.oauth2.provider.token.store.redis.RedisTokenStoreSerializationStrategy;

import java.nio.charset.Charset;
import java.nio.charset.StandardCharsets;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class FastjsonRedisTokenStoreSerializationStrategy implements RedisTokenStoreSerializationStrategy {
    private static ParserConfig config = new ParserConfig();
    static {
        init();
    }

    protected static void init() {
        //自定义oauth2序列化：DefaultOAuth2RefreshToken 没有setValue方法，会导致JSON序列化为null
        config.setAutoTypeSupport(true);//开启AutoType
        //自定义DefaultOauth2RefreshTokenSerializer反序列化
        config.putDeserializer(DefaultOAuth2RefreshToken.class, new DefaultOauth2RefreshTokenSerializer());
        //自定义OAuth2Authentication反序列化
        config.putDeserializer(OAuth2Authentication.class, new OAuth2AuthenticationSerializer());
        //添加autotype白名单
        config.addAccept(&quot;org.springframework.security.oauth2.provider.&quot;);
        config.addAccept(&quot;org.springframework.security.oauth2.provider.client&quot;);

        TypeUtils.loadClass(&quot;org.springframework.security.oauth2.provider.OAuth2Authentication&quot;);
        TypeUtils.loadClass(&quot;org.springframework.security.oauth2.provider.client.BaseClientDetails&quot;);

        config.addAccept(&quot;org.springframework.security.oauth2.common.&quot;);
        TypeUtils.loadClass(&quot;org.springframework.security.oauth2.common.DefaultOAuth2AccessToken&quot;);
        TypeUtils.loadClass(&quot;org.springframework.security.oauth2.common.DefaultExpiringOAuth2RefreshToken&quot;);

        config.addAccept(&quot;com.yunzainfo.cloud.mars.common.security.YzUser&quot;);
        config.addAccept(&quot;com.yunzainfo.cloud.mars.common.security.User&quot;);
        TypeUtils.loadClass(&quot;com.yunzainfo.cloud.mars.common.security.YzUser&quot;);
        TypeUtils.loadClass(&quot;com.yunzainfo.cloud.mars.common.security.User&quot;);

        config.addAccept(&quot;org.springframework.security.web.authentication.preauth&quot;);
        TypeUtils.loadClass(&quot;org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationToken&quot;);
        config.addAccept(&quot;java.util.Collections$UnmodifiableMap&quot;);
    }

    @Override
    public &lt;T&gt; T deserialize(byte[] bytes, Class&lt;T&gt; aClass) {
        Preconditions.checkArgument(aClass != null,
                &quot;clazz can't be null&quot;);
        if (bytes == null || bytes.length == 0) {
            return null;
        }

        try {
            return JSON.parseObject(new String(bytes, IOUtils.UTF8), aClass, config);
        } catch (Exception ex) {
            throw new SerializationException(&quot;Could not serialize: &quot; + ex.getMessage(), ex);
        }
    }

    @Override
    public String deserializeString(byte[] bytes) {
        if (bytes == null || bytes.length == 0) {
            return null;
        }
        return new String(bytes, IOUtils.UTF8);
    }

    @Override
    public byte[] serialize(Object o) {
        if (o == null) {
            return new byte[0];
        }
        if(o instanceof OAuth2Authentication){
            OAuth2Authentication oAuth2Authentication=(OAuth2Authentication)o;
            OAuth2Request oAuth2Request = oAuth2Authentication.getOAuth2Request();
            Map&lt;String, String&gt; requestParameters = oAuth2Request.getRequestParameters();
            HashMap&lt;String, String&gt; newRequestParamters = new HashMap&lt;&gt;();
            newRequestParamters.putAll(requestParameters);
            ReflectUtil.setFieldValue(oAuth2Request,&quot;requestParameters&quot;,newRequestParamters);
        }
        try {
            byte[] bytes = JSON.toJSONBytes(o, SerializerFeature.WriteClassName,
                    SerializerFeature.DisableCircularReferenceDetect);
            String save = new String(bytes);
            String replace = save.replaceAll(&quot;com.yunzainfo.cloud.mars.common.security.YzUser&quot;, &quot;com.yunzainfo.cloud.mars.common.security.User&quot;);
            return replace.getBytes(StandardCharsets.UTF_8);
        } catch (Exception ex) {
            throw new SerializationException(&quot;Could not serialize: &quot; + ex.getMessage(), ex);
        }
    }

    @Override
    public byte[] serialize(String data) {
        if (data == null || data.length() == 0) {
            return new byte[0];
        }

        return data.getBytes(Charset.forName(&quot;utf-8&quot;));
    }

}

</code></pre>
<h2 id="defaultoauth2refreshtokenserializer-自定义默认的刷新token序列化工具类">DefaultOauth2RefreshTokenSerializer 自定义默认的刷新token序列化工具类</h2>
<pre><code class="language-java">
import com.alibaba.fastjson.JSONObject;
import com.alibaba.fastjson.parser.DefaultJSONParser;
import com.alibaba.fastjson.parser.deserializer.ObjectDeserializer;
import org.springframework.security.oauth2.common.DefaultOAuth2RefreshToken;

import java.lang.reflect.Type;

public class DefaultOauth2RefreshTokenSerializer implements ObjectDeserializer {

    @Override
    public &lt;T&gt; T deserialze(DefaultJSONParser parser, Type type, Object fieldName) {
        if (type == DefaultOAuth2RefreshToken.class) {
            JSONObject jsonObject = parser.parseObject();
            String tokenId = jsonObject.getString(&quot;value&quot;);
            DefaultOAuth2RefreshToken refreshToken = new DefaultOAuth2RefreshToken(tokenId);
            return (T) refreshToken;
        }
        return null;
    }

    @Override
    public int getFastMatchToken() {
        return 0;
    }

}
</code></pre>
<h2 id="oauth2authenticationserializer-自定义oauth2认证序列化工具类">OAuth2AuthenticationSerializer 自定义OAuth2认证序列化工具类</h2>
<pre><code class="language-java">package com.yunzainfo.cloud.mars.common.security;

import com.alibaba.fastjson.JSONObject;
import com.alibaba.fastjson.TypeReference;
import com.alibaba.fastjson.parser.DefaultJSONParser;
import com.alibaba.fastjson.parser.Feature;
import com.alibaba.fastjson.parser.deserializer.ObjectDeserializer;
import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;
import org.springframework.security.core.Authentication;
import org.springframework.security.core.GrantedAuthority;
import org.springframework.security.core.authority.SimpleGrantedAuthority;
import org.springframework.security.oauth2.provider.OAuth2Authentication;
import org.springframework.security.oauth2.provider.OAuth2Request;
import org.springframework.security.oauth2.provider.TokenRequest;

import java.io.Serializable;
import java.lang.reflect.Type;
import java.util.*;


public class OAuth2AuthenticationSerializer implements ObjectDeserializer {

    @Override
    public &lt;T&gt; T deserialze(DefaultJSONParser parser, Type type, Object fieldName) {
        if (type == OAuth2Authentication.class) {

            try {
                Object o = parse(parser);
                if (o == null) {
                    return null;
                } else if (o instanceof OAuth2Authentication) {
                    return (T) o;
                }

                JSONObject jsonObject = (JSONObject) o;
                OAuth2Request request = parseOAuth2Request(jsonObject);

                Object autoType = jsonObject.get(&quot;userAuthentication&quot;);
                Authentication userAuthentication = jsonObject.getObject(&quot;userAuthentication&quot;, (Type) autoType.getClass());
                if (userAuthentication instanceof UsernamePasswordAuthenticationToken) {
                    //转换user=&gt;&gt;YzUser(YzUser反序列化会失败，在存储的时候将YzUser转成了User，所以要在这里转回来，否则SecutiryUtils的静态方法会抛类型转换异常)
                    User user = (User) (userAuthentication).getPrincipal();
                    List menu = user.getMenu();
                    Collections.sort(menu);
                    sortMenuByDisplayIndex(menu);//排顺序
                    YzUser yzUser = new YzUser(user.getUsername(), user.getRealname(), &quot;此方法不提供密码&quot;, user.getUserId(), user.getUserCode(), user.getDeptId(), user.getDeptName(), menu, user.getRoles(), user.getUserType(), user.getAuthorities(), user.getAvatarId(), user.getTenantId());
                    UsernamePasswordAuthenticationToken usernamePasswordAuthenticationToken = new UsernamePasswordAuthenticationToken(yzUser, yzUser.getPassword(), yzUser.getAuthorities());
                    usernamePasswordAuthenticationToken.eraseCredentials();
                    userAuthentication = usernamePasswordAuthenticationToken;
                }
                return (T) new OAuth2Authentication(request, userAuthentication);
            } catch (Exception e) {
                e.printStackTrace();
            }
            return null;
        }
        return null;
    }
    private void sortMenuByDisplayIndex(Collection&lt;Menu&gt; menus) {
        for (Menu menu : menus) {
            Set&lt;Menu&gt; children = menu.getChildren();
            if (children != null &amp;&amp; children.size() != 0) {
                Set&lt;Menu&gt; newSet = new TreeSet&lt;&gt;();
                newSet.addAll(children);
                menu.setChildren(newSet);
                sortMenuByDisplayIndex(newSet);
            }
        }
    }

    private OAuth2Request parseOAuth2Request(JSONObject jsonObject) {
        JSONObject json = jsonObject.getObject(&quot;oAuth2Request&quot;, JSONObject.class);
        Map&lt;String, String&gt; requestParameters = json.getObject(&quot;requestParameters&quot;, Map.class);
        String clientId = json.getString(&quot;clientId&quot;);
        String grantType = json.getString(&quot;grantType&quot;);
        String redirectUri = json.getString(&quot;redirectUri&quot;);
        Boolean approved = json.getBoolean(&quot;approved&quot;);
        Set&lt;String&gt; responseTypes = json
                .getObject(&quot;responseTypes&quot;, new TypeReference&lt;HashSet&lt;String&gt;&gt;() {
                });
        Set&lt;String&gt; scope = json.getObject(&quot;scope&quot;, new TypeReference&lt;HashSet&lt;String&gt;&gt;() {
        });
        Set&lt;String&gt; authorities = json.getObject(&quot;authorities&quot;, new TypeReference&lt;HashSet&lt;String&gt;&gt;() {
        });
        Set&lt;GrantedAuthority&gt; grantedAuthorities = new HashSet&lt;&gt;(0);
        if (authorities != null &amp;&amp; !authorities.isEmpty()) {
            authorities.forEach(s -&gt; grantedAuthorities.add(new SimpleGrantedAuthority(s)));
        }
        Set&lt;String&gt; resourceIds = json
                .getObject(&quot;resourceIds&quot;, new TypeReference&lt;HashSet&lt;String&gt;&gt;() {
                });
        Map&lt;String, Serializable&gt; extensions = json
                .getObject(&quot;extensions&quot;, new TypeReference&lt;HashMap&lt;String, Serializable&gt;&gt;() {
                });

        OAuth2Request request = new OAuth2Request(requestParameters, clientId,
                grantedAuthorities, approved, scope, resourceIds, redirectUri, responseTypes, extensions);
        TokenRequest tokenRequest = new TokenRequest(requestParameters, clientId, scope, grantType);
        request.refresh(tokenRequest);
        return request;
    }


    @Override
    public int getFastMatchToken() {
        return 0;
    }

    private Object parse(DefaultJSONParser parse) {
        JSONObject object = new JSONObject(parse.lexer.isEnabled(Feature.OrderedField));
        Object parsedObject = parse.parseObject((Map) object);
        if (parsedObject instanceof JSONObject) {
            return (JSONObject) parsedObject;
        } else if (parsedObject instanceof OAuth2Authentication) {
            return parsedObject;
        } else {
            return parsedObject == null ? null : new JSONObject((Map) parsedObject);
        }
    }

}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[多租户系统redis 缓存]]></title>
        <id>https://oldcamel.run/post/duo-zu-hu-xi-tong-redis-huan-cun/</id>
        <link href="https://oldcamel.run/post/duo-zu-hu-xi-tong-redis-huan-cun/">
        </link>
        <updated>2021-06-28T09:28:38.000Z</updated>
        <content type="html"><![CDATA[<h2 id="多租户系统用cacheable做接口缓存为了避免缓存数据混乱需要做缓存数据的租户隔离">多租户系统用@Cacheable做接口缓存,为了避免缓存数据混乱，需要做缓存数据的租户隔离。</h2>
<h3 id="缓存过程源码分析">缓存过程源码分析：</h3>
<ul>
<li>
<ol>
<li>EnableCaching注解<br>
<img src="https://oldcamel.run/post-images/1624872845862.png" alt="" loading="lazy"><br>
EnableCaching中引入了@Import({CachingConfigurationSelector.class})</li>
</ol>
</li>
<li>
<p>2.CachingConfigurationSelector<br>
<img src="https://oldcamel.run/post-images/1624873054168.png" alt="" loading="lazy"></p>
<p>getProxyImports方法中设置了ProxyCachingConfiguration 代理配置类</p>
</li>
<li>
<ol start="3">
<li>CacheInterceptor<br>
<img src="https://oldcamel.run/post-images/1624873141831.png" alt="" loading="lazy"><br>
ProxyCachingConfiguration中配置了缓存拦截器CacheInterceptor类</li>
</ol>
</li>
<li>
<p>4.CacheAspectSupport<br>
<img src="https://oldcamel.run/post-images/1624873286826.png" alt="" loading="lazy"><br>
打开CacheInterceptor的父类CacheAspectSupport。<br>
<img src="https://oldcamel.run/post-images/1624873358773.png" alt="" loading="lazy"><br>
ProxyCachingConfiguration中调用的configure方法设置了缓存处理器 SimpleCacheResolver。</p>
</li>
<li>
<p>5.获取缓存 key getCacheNames方法<br>
<img src="https://oldcamel.run/post-images/1624873922073.png" alt="" loading="lazy"></p>
</li>
</ul>
<h3 id="修改思路">修改思路</h3>
<p>修改getCacheNames方法，添加租户id作为前缀</p>
<p>现在直接复制源码做了修改，所有要修改的类添加统一前缀<br>
<img src="https://oldcamel.run/post-images/1624874053089.png" alt="" loading="lazy"></p>
<h4 id="关键地方记录">关键地方记录：</h4>
<p><img src="https://oldcamel.run/post-images/1624874095560.png" alt="" loading="lazy"><br>
<img src="https://oldcamel.run/post-images/1624874126630.png" alt="" loading="lazy"><br>
<img src="https://oldcamel.run/post-images/1624874148169.png" alt="" loading="lazy"><br>
<img src="https://oldcamel.run/post-images/1624874197651.png" alt="" loading="lazy"><br>
<img src="https://oldcamel.run/post-images/1624874233299.png" alt="" loading="lazy"></p>
<h3 id="后续">后续</h3>
<p><img src="https://oldcamel.run/post-images/1624874340646.png" alt="" loading="lazy"><br>
改完才发现，直接在RedisCacheConfigutation类中定义一个CacheResolver 的bean应该也是可以的。暂时先不改了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PostgreSql 数据类型]]></title>
        <id>https://oldcamel.run/post/postgresql-shu-ju-lei-xing/</id>
        <link href="https://oldcamel.run/post/postgresql-shu-ju-lei-xing/">
        </link>
        <updated>2021-06-01T07:15:34.000Z</updated>
        <content type="html"><![CDATA[<h1 id="数值类型">数值类型</h1>
<p>数值类型由 2 字节、4 字节或 8 字节的整数以及 4 字节或 8 字节的浮点数和可选精度的十进制数组成。</p>
<table>
<thead>
<tr>
<th>名字</th>
<th>存储长度</th>
<th>描述</th>
<th>范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>smallint</td>
<td>2 字节</td>
<td>小范围整数</td>
<td>-32768 到 +32767</td>
</tr>
<tr>
<td>integer</td>
<td>4 字节</td>
<td>常用的整数</td>
<td>-2147483648 到 +2147483647</td>
</tr>
<tr>
<td>bigint</td>
<td>8 字节</td>
<td>大范围整数</td>
<td>-9223372036854775808 到 +9223372036854775807</td>
</tr>
<tr>
<td>decimal</td>
<td>可变长</td>
<td>用户指定的精度，精确</td>
<td>小数点前 131072 位；小数点后 16383 位</td>
</tr>
<tr>
<td>numeric</td>
<td>可变长</td>
<td>用户指定的精度，精确</td>
<td>小数点前 131072 位；小数点后 16383 位</td>
</tr>
<tr>
<td>real</td>
<td>4 字节</td>
<td>可变精度，不精确</td>
<td>6 位十进制数字精度</td>
</tr>
<tr>
<td>double precision</td>
<td>8 字节</td>
<td>可变精度，不精确</td>
<td>15 位十进制数字精度</td>
</tr>
<tr>
<td>smallserial</td>
<td>2 字节</td>
<td>自增的小范围整数</td>
<td>1 到 32767</td>
</tr>
<tr>
<td>serial</td>
<td>4 字节</td>
<td>自增整数</td>
<td>1 到 2147483647</td>
</tr>
<tr>
<td>bigserial</td>
<td>8 字节</td>
<td>自增的大范围整数</td>
<td>1 到 9223372036854775807</td>
</tr>
</tbody>
</table>
<h1 id="货币类型">货币类型</h1>
<p>money 类型存储带有固定小数精度的货币金额。<br>
numeric、int 和 bigint 类型的值可以转换为 money，不建议使用浮点数来处理处理货币类型，因为存在舍入错误的可能性。</p>
<table>
<thead>
<tr>
<th>名字</th>
<th>存储长度</th>
<th>描述</th>
<th>范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>money</td>
<td>8字节</td>
<td>货币金额</td>
<td>-92233720368547758.08 到 +92233720368547758.07</td>
</tr>
</tbody>
</table>
<h1 id="字符类型">字符类型</h1>
<table>
<thead>
<tr>
<th>序号</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>character varying(n), varchar(n)变长，有长度限制</td>
</tr>
<tr>
<td>2</td>
<td>character(n), char(n) 定长,不足补空白</td>
</tr>
<tr>
<td>3</td>
<td>text  变长，无长度限制</td>
</tr>
</tbody>
</table>
<h1 id="日期时间类型">日期/时间类型</h1>
<table>
<thead>
<tr>
<th>名字</th>
<th>存储空间</th>
<th>描述</th>
<th>最低值</th>
<th>最高值</th>
<th>分辨率</th>
</tr>
</thead>
<tbody>
<tr>
<td>timestamp [ (p) ] [ without time zone ]</td>
<td>8 字节</td>
<td>日期和时间(无时区)</td>
<td>4713 BC</td>
<td>294276 AD</td>
<td>1 毫秒 / 14 位</td>
</tr>
<tr>
<td>timestamp [ (p) ] with time zone</td>
<td>8 字节</td>
<td>日期和时间，有时区</td>
<td>4713 BC</td>
<td>294276 AD</td>
<td>1 毫秒 / 14 位</td>
</tr>
<tr>
<td>date</td>
<td>4 字节</td>
<td>只用于日期</td>
<td>4713 BC</td>
<td>5874897 AD</td>
<td>1 天</td>
</tr>
<tr>
<td>time [ (p) ] [ without time zone ]</td>
<td>8 字节</td>
<td>只用于一日内时间</td>
<td>00:00:00</td>
<td>24:00:00</td>
<td>1 毫秒 / 14 位</td>
</tr>
<tr>
<td>time [ (p) ] with time zone</td>
<td>12 字节</td>
<td>只用于一日内时间，带时区</td>
<td>00:00:00+1459</td>
<td>24:00:00-1459</td>
<td>1 毫秒 / 14 位</td>
</tr>
<tr>
<td>interval [ fields ] [ (p) ]</td>
<td>12 字节</td>
<td>时间间隔</td>
<td>-178000000 年</td>
<td>178000000 年</td>
<td>1 毫秒 / 14 位</td>
</tr>
</tbody>
</table>
<h1 id="布尔类型">布尔类型</h1>
<p>PostgreSQL 支持标准的 boolean 数据类型。</p>
<p>boolean 有&quot;true&quot;(真)或&quot;false&quot;(假)两个状态， 第三种&quot;unknown&quot;(未知)状态，用 NULL 表示。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>存储格式</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>boolean</td>
<td>1 字节</td>
<td>true/false</td>
</tr>
</tbody>
</table>
<h1 id="枚举类型">枚举类型</h1>
<p>枚举类型是一个包含静态和值的有序集合的数据类型。</p>
<p>PostgtesSQL中的枚举类型类似于 C 语言中的 enum 类型。</p>
<p>与其他类型不同的是枚举类型需要使用 CREATE TYPE 命令创建。</p>
<p><code>CREATE TYPE mood AS ENUM ('sad', 'ok', 'happy');</code><br>
创建一周中的几天，如下所示:<br>
<code>CREATE TYPE week AS ENUM ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun');</code><br>
就像其他类型一样，一旦创建，枚举类型可以用于表和函数定义。</p>
<pre><code class="language-java">CREATE TYPE mood AS ENUM ('sad', 'ok', 'happy');
CREATE TABLE person (
    name text,
    current_mood mood
);
INSERT INTO person VALUES ('Moe', 'happy');
SELECT * FROM person WHERE current_mood = 'happy';
 name | current_mood 
------+--------------
 Moe  | happy
(1 row)
</code></pre>
<h1 id="几何类型">几何类型</h1>
<p>几何数据类型表示二维的平面物体。最基本的类型：点。它是其它类型的基础。</p>
<table>
<thead>
<tr>
<th>名字</th>
<th>存储空间</th>
<th>说明</th>
<th>表现形式</th>
</tr>
</thead>
<tbody>
<tr>
<td>point</td>
<td>16 字节</td>
<td>平面中的点</td>
<td>(x,y)</td>
</tr>
<tr>
<td>line</td>
<td>32 字节</td>
<td>(无穷)直线(未完全实现)</td>
<td>((x1,y1),(x2,y2))</td>
</tr>
<tr>
<td>lseg</td>
<td>32 字节</td>
<td>(有限)线段</td>
<td>((x1,y1),(x2,y2))</td>
</tr>
<tr>
<td>box</td>
<td>32 字节</td>
<td>矩形</td>
<td>((x1,y1),(x2,y2))</td>
</tr>
<tr>
<td>path</td>
<td>16+16n 字节</td>
<td>闭合路径(与多边形类似)</td>
<td>((x1,y1),...)</td>
</tr>
<tr>
<td>path</td>
<td>16+16n 字节</td>
<td>开放路径</td>
<td>[(x1,y1),...]</td>
</tr>
<tr>
<td>polygon</td>
<td>40+16n 字节</td>
<td>多边形(与闭合路径相似)</td>
<td>((x1,y1),...)</td>
</tr>
<tr>
<td>circle</td>
<td>24 字节</td>
<td>圆	&lt;(x,y),r&gt;</td>
<td>(圆心和半径)</td>
</tr>
</tbody>
</table>
<h1 id="网络地址类型">网络地址类型</h1>
<p>PostgreSQL 提供用于存储 IPv4 、IPv6 、MAC 地址的数据类型。用这些数据类型存储网络地址比用纯文本类型好， 因为这些类型提供输入错误检查和特殊的操作和功能。</p>
<table>
<thead>
<tr>
<th>名字</th>
<th>存储空间</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>cidr</td>
<td>7 或 19 字节</td>
<td>IPv4 或 IPv6 网络</td>
</tr>
<tr>
<td>inet</td>
<td>7 或 19 字节</td>
<td>IPv4 或 IPv6 主机和网络</td>
</tr>
<tr>
<td>macaddr</td>
<td>6 字节</td>
<td>MAC 地址</td>
</tr>
</tbody>
</table>
<p>在对 inet 或 cidr 数据类型进行排序的时候， IPv4 地址总是排在 IPv6 地址前面，包括那些封装或者是映射在 IPv6 地址里的 IPv4 地址， 比如 ::10.2.3.4 或 ::ffff:10.4.3.2。</p>
<h1 id="位串类型">位串类型</h1>
<p>位串就是一串 1 和 0 的字符串。它们可以用于存储和直观化位掩码。 我们有两种 SQL 位类型：bit(n) 和bit varying(n)， 这里的n是一个正整数。</p>
<p>bit 类型的数据必须准确匹配长度 n， 试图存储短些或者长一些的数据都是错误的。bit varying 类型数据是最长 n 的变长类型；更长的串会被拒绝。 写一个没有长度的bit 等效于 bit(1)， 没有长度的 bit varying 意思是没有长度限制。</p>
<h1 id="文本搜索类型">文本搜索类型</h1>
<p>全文检索即通过自然语言文档的集合来找到那些匹配一个查询的检索。<br>
PostgreSQL 提供了两种数据类型用于支持全文检索：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>名字 &amp; 描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>tsvector tsvector 的值是一个无重复值的 lexemes 排序列表， 即一些同一个词的不同变种的标准化。</td>
</tr>
</tbody>
</table>
<p>2|	tsquery tsquery 存储用于检索的词汇，并且使用布尔操作符 &amp;(AND)，|(OR)和!(NOT) 来组合它们，括号用来强调操作符的分组。</p>
<h1 id="uuid-类型">UUID 类型</h1>
<p>uuid 数据类型用来存储 RFC 4122，ISO/IEF 9834-8:2005 以及相关标准定义的通用唯一标识符（UUID）。 （一些系统认为这个数据类型为全球唯一标识符，或GUID。） 这个标识符是一个由算法产生的 128 位标识符，使它不可能在已知使用相同算法的模块中和其他方式产生的标识符相同。 因此，对分布式系统而言，这种标识符比序列能更好的提供唯一性保证，因为序列只能在单一数据库中保证唯一。</p>
<p>UUID 被写成一个小写十六进制数字的序列，由分字符分成几组， 特别是一组8位数字+3组4位数字+一组12位数字，总共 32 个数字代表 128 位， 一个这种标准的 UUID 例子如下：<br>
<code>a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11</code></p>
<h1 id="xml-类型">XML 类型</h1>
<p>xml 数据类型可以用于存储XML数据。 将 XML 数据存到 text 类型中的优势在于它能够为结构良好性来检查输入值， 并且还支持函数对其进行类型安全性检查。 要使用这个数据类型，编译时必须使用 configure --with-libxml。</p>
<p>xml 可以存储由XML标准定义的格式良好的&quot;文档&quot;， 以及由 XML 标准中的 XMLDecl? content 定义的&quot;内容&quot;片段， 大致上，这意味着内容片段可以有多个顶级元素或字符节点。 xmlvalue IS DOCUMENT 表达式可以用来判断一个特定的 xml 值是一个完整的文件还是内容片段。</p>
<h2 id="创建xml值">创建XML值</h2>
<p>使用函数 xmlparse: 来从字符数据产生 xml 类型的值：</p>
<pre><code>XMLPARSE (DOCUMENT '&lt;?xml version=&quot;1.0&quot;?&gt;&lt;book&gt;&lt;title&gt;Manual&lt;/title&gt;&lt;chapter&gt;...&lt;/chapter&gt;&lt;/book&gt;')
XMLPARSE (CONTENT 'abc&lt;foo&gt;bar&lt;/foo&gt;&lt;bar&gt;foo&lt;/bar&gt;')
</code></pre>
<h1 id="json-类型">JSON 类型</h1>
<p>json 数据类型可以用来存储 JSON（JavaScript Object Notation）数据， 这样的数据也可以存储为 text，但是 json 数据类型更有利于检查每个存储的数值是可用的 JSON 值。</p>
<p>此外还有相关的函数来处理 json 数据：</p>
<table>
<thead>
<tr>
<th>实例</th>
<th>实例结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>array_to_json('{{1,5},{99,100}}'::int[])</td>
<td>[[1,5],[99,100]]</td>
</tr>
<tr>
<td>row_to_json(row(1,'foo'))</td>
<td>{&quot;f1&quot;:1,&quot;f2&quot;:&quot;foo&quot;}</td>
</tr>
</tbody>
</table>
<h1 id="数组类型">数组类型</h1>
<p>PostgreSQL 允许将字段定义成变长的多维数组。</p>
<p>数组类型可以是任何基本类型或用户定义类型，枚举类型或复合类型。</p>
<h2 id="声明数组">声明数组</h2>
<p>创建表的时候，我们可以声明数组，方式如下：</p>
<pre><code>CREATE TABLE sal_emp (
    name            text,
    pay_by_quarter  integer[],
    schedule        text[][]
);
</code></pre>
<p>pay_by_quarter 为一维整型数组、schedule 为二维文本类型数组。</p>
<p>我们也可以使用 &quot;ARRAY&quot; 关键字，如下所示：</p>
<pre><code>CREATE TABLE sal_emp (
   name text,
   pay_by_quarter integer ARRAY[4],
   schedule text[][]
);
</code></pre>
<h2 id="插入值">插入值</h2>
<p>插入值使用花括号 {}，元素在 {} 使用逗号隔开：</p>
<pre><code>INSERT INTO sal_emp
    VALUES ('Bill',
    '{10000, 10000, 10000, 10000}',
    '{{&quot;meeting&quot;, &quot;lunch&quot;}, {&quot;training&quot;, &quot;presentation&quot;}}');

INSERT INTO sal_emp
    VALUES ('Carol',
    '{20000, 25000, 25000, 25000}',
    '{{&quot;breakfast&quot;, &quot;consulting&quot;}, {&quot;meeting&quot;, &quot;lunch&quot;}}');
</code></pre>
<h2 id="访问数组">访问数组</h2>
<p>现在我们可以在这个表上运行一些查询。</p>
<p>首先，我们演示如何访问数组的一个元素。 这个查询检索在第二季度薪水变化的雇员名：</p>
<pre><code>SELECT name FROM sal_emp WHERE pay_by_quarter[1] &lt;&gt; pay_by_quarter[2];

 name
-------
 Carol
(1 row)
</code></pre>
<p>数组的下标数字是写在方括弧内的。</p>
<h2 id="修改数组">修改数组</h2>
<p>我们可以对数组的值进行修改：</p>
<p><code>UPDATE sal_emp SET pay_by_quarter = '{25000,25000,27000,27000}' WHERE name = 'Carol';</code><br>
或者使用 ARRAY 构造器语法：<br>
<code>UPDATE sal_emp SET pay_by_quarter = ARRAY[25000,25000,27000,27000] WHERE name = 'Carol';</code></p>
<h2 id="数组中检索">数组中检索</h2>
<p>要搜索一个数组中的数值，你必须检查该数组的每一个值。</p>
<p>比如：</p>
<pre><code>SELECT * FROM sal_emp WHERE pay_by_quarter[1] = 10000 OR
                            pay_by_quarter[2] = 10000 OR
                            pay_by_quarter[3] = 10000 OR
                            pay_by_quarter[4] = 10000;
</code></pre>
<p>另外，你可以用下面的语句找出数组中所有元素值都等于 10000 的行：</p>
<pre><code>SELECT * FROM sal_emp WHERE 10000 = ALL (pay_by_quarter);
</code></pre>
<p>或者，可以使用 generate_subscripts 函数。例如：</p>
<pre><code>SELECT * FROM
   (SELECT pay_by_quarter,
           generate_subscripts(pay_by_quarter, 1) AS s
      FROM sal_emp) AS foo
 WHERE pay_by_quarter[s] = 10000;
</code></pre>
<h1 id="复合类型">复合类型</h1>
<p>复合类型表示一行或者一条记录的结构； 它实际上只是一个字段名和它们的数据类型的列表。PostgreSQL 允许像简单数据类型那样使用复合类型。比如，一个表的某个字段可以声明为一个复合类型。</p>
<h2 id="声明复合类型">声明复合类型</h2>
<p>下面是两个定义复合类型的简单例子：</p>
<pre><code>CREATE TYPE complex AS (
   r       double precision,
   i       double precision
);

CREATE TYPE inventory_item AS (
   name            text,
   supplier_id     integer,
   price           numeric
);
</code></pre>
<p>语法类似于 CREATE TABLE，只是这里只可以声明字段名字和类型。</p>
<p>定义了类型，我们就可以用它创建表：</p>
<pre><code>CREATE TABLE on_hand (
   item      inventory_item,
   count     integer
);

INSERT INTO on_hand VALUES (ROW('fuzzy dice', 42, 1.99), 1000);
</code></pre>
<h2 id="复合类型值输入">复合类型值输入</h2>
<p>要以文本常量书写复合类型值，在圆括弧里包围字段值并且用逗号分隔他们。 你可以在任何字段值周围放上双引号，如果值本身包含逗号或者圆括弧， 你必须用双引号括起。</p>
<p>复合类型常量的一般格式如下：</p>
<p><code>'( val1 , val2 , ... )'</code><br>
一个例子是:<br>
<code>'(&quot;fuzzy dice&quot;,42,1.99)'</code></p>
<h2 id="访问复合类型">访问复合类型</h2>
<p>要访问复合类型字段的一个域，我们写出一个点以及域的名字， 非常类似从一个表名字里选出一个字段。实际上，因为实在太像从表名字中选取字段， 所以我们经常需要用圆括弧来避免分析器混淆。比如，你可能需要从on_hand 例子表中选取一些子域，像下面这样：</p>
<pre><code>SELECT item.name FROM on_hand WHERE item.price &gt; 9.99;
</code></pre>
<p>这样将不能工作，因为根据 SQL 语法，item是从一个表名字选取的， 而不是一个字段名字。你必须像下面这样写：</p>
<pre><code>SELECT (item).name FROM on_hand WHERE (item).price &gt; 9.99;
</code></pre>
<p>或者如果你也需要使用表名字(比如，在一个多表查询里)，那么这么写：</p>
<pre><code>SELECT (on_hand.item).name FROM on_hand WHERE (on_hand.item).price &gt; 9.99;
</code></pre>
<p>现在圆括弧对象正确地解析为一个指向item字段的引用，然后就可以从中选取子域。</p>
<h1 id="范围类型">范围类型</h1>
<p>范围数据类型代表着某一元素类型在一定范围内的值。</p>
<p>例如，timestamp 范围可能被用于代表一间会议室被预定的时间范围。</p>
<p>PostgreSQL 内置的范围类型有：</p>
<ul>
<li>int4range — integer的范围</li>
<li>int8range —bigint的范围</li>
<li>numrange —numeric的范围</li>
<li>tsrange —timestamp without time zone的范围</li>
<li>tstzrange —timestamp with time zone的范围</li>
<li>daterange —date的范围<br>
此外，你可以定义你自己的范围类型。</li>
</ul>
<pre><code>CREATE TABLE reservation (room int, during tsrange);
INSERT INTO reservation VALUES
    (1108, '[2010-01-01 14:30, 2010-01-01 15:30)');

-- 包含
SELECT int4range(10, 20) @&gt; 3;

-- 重叠
SELECT numrange(11.1, 22.2) &amp;&amp; numrange(20.0, 30.0);

-- 提取上边界
SELECT upper(int8range(15, 25));

-- 计算交叉
SELECT int4range(10, 20) * int4range(15, 25);

-- 范围是否为空
SELECT isempty(numrange(1, 5));
</code></pre>
<p>范围值的输入必须遵循下面的格式：</p>
<pre><code>(下边界,上边界)
(下边界,上边界]
[下边界,上边界)
[下边界,上边界]
空
</code></pre>
<p>圆括号或者方括号显示下边界和上边界是不包含的还是包含的。注意最后的格式是 空，代表着一个空的范围（一个不含有值的范围）。</p>
<pre><code>-- 包括3，不包括7，并且包括二者之间的所有点
SELECT '[3,7)'::int4range;

-- 不包括3和7，但是包括二者之间所有点
SELECT '(3,7)'::int4range;

-- 只包括单一值4
SELECT '[4,4]'::int4range;

-- 不包括点（被标准化为‘空’）
SELECT '[4,4)'::int4range;
</code></pre>
<h1 id="对象标识符类型">对象标识符类型</h1>
<p>PostgreSQL 在内部使用对象标识符(OID)作为各种系统表的主键。</p>
<p>同时，系统不会给用户创建的表增加一个 OID 系统字段(除非在建表时声明了WITH OIDS 或者配置参数default_with_oids设置为开启)。oid 类型代表一个对象标识符。除此以外 oid 还有几个别名：regproc, regprocedure, regoper, regoperator, regclass, regtype, regconfig, 和regdictionary。</p>
<table>
<thead>
<tr>
<th>名字</th>
<th>引用</th>
<th>描述</th>
<th>数值例子</th>
</tr>
</thead>
<tbody>
<tr>
<td>oid</td>
<td>任意</td>
<td>数字化的对象标识符</td>
<td>564182</td>
</tr>
<tr>
<td>regproc</td>
<td>pg_proc</td>
<td>函数名字</td>
<td>sum</td>
</tr>
<tr>
<td>regprocedure</td>
<td>pg_proc</td>
<td>带参数类型的函数</td>
<td>sum(int4)</td>
</tr>
<tr>
<td>regoper</td>
<td>pg_operator</td>
<td>操作符名</td>
<td>+</td>
</tr>
<tr>
<td>regoperator</td>
<td>pg_operator</td>
<td>带参数类型的操作符</td>
<td>*(integer,integer) 或 -(NONE,integer)</td>
</tr>
<tr>
<td>regclass</td>
<td>pg_class</td>
<td>关系名</td>
<td>pg_type</td>
</tr>
<tr>
<td>regtype</td>
<td>pg_type</td>
<td>数据类型名</td>
<td>integer</td>
</tr>
<tr>
<td>regconfig</td>
<td>pg_ts_config</td>
<td>文本搜索配置</td>
<td>english</td>
</tr>
<tr>
<td>regdictionary</td>
<td>pg_ts_dict</td>
<td>文本搜索字典</td>
<td>simple</td>
</tr>
</tbody>
</table>
<h1 id="伪类型">伪类型</h1>
<p>PostgreSQL类型系统包含一系列特殊用途的条目， 它们按照类别来说叫做伪类型。伪类型不能作为字段的数据类型， 但是它可以用于声明一个函数的参数或者结果类型。 伪类型在一个函数不只是简单地接受并返回某种SQL 数据类型的情况下很有用。</p>
<table>
<thead>
<tr>
<th>名字</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>any</td>
<td>表示一个函数接受任何输入数据类型。</td>
</tr>
<tr>
<td>anyelement</td>
<td>表示一个函数接受任何数据类型。</td>
</tr>
<tr>
<td>anyarray</td>
<td>表示一个函数接受任意数组数据类型。</td>
</tr>
<tr>
<td>anynonarray</td>
<td>表示一个函数接受任意非数组数据类型。</td>
</tr>
<tr>
<td>anyenum</td>
<td>表示一个函数接受任意枚举数据类型。</td>
</tr>
<tr>
<td>anyrange</td>
<td>表示一个函数接受任意范围数据类型。</td>
</tr>
<tr>
<td>cstring</td>
<td>表示一个函数接受或者返回一个空结尾的 C 字符串。</td>
</tr>
<tr>
<td>internal</td>
<td>表示一个函数接受或者返回一种服务器内部的数据类型。</td>
</tr>
<tr>
<td>language_handler</td>
<td>一个过程语言调用处理器声明为返回language_handler。</td>
</tr>
<tr>
<td>fdw_handler</td>
<td>一个外部数据封装器声明为返回fdw_handler。</td>
</tr>
<tr>
<td>record</td>
<td>标识一个函数返回一个未声明的行类型。</td>
</tr>
<tr>
<td>trigger</td>
<td>一个触发器函数声明为返回trigger。</td>
</tr>
<tr>
<td>void</td>
<td>表示一个函数不返回数值。</td>
</tr>
<tr>
<td>opaque</td>
<td>一个已经过时的类型，以前用于所有上面这些用途。</td>
</tr>
</tbody>
</table>
<p>转载地址：https://m.runoob.com/postgresql/postgresql-data-type.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[4.0 新的开端]]></title>
        <id>https://oldcamel.run/post/40-xin-de-kai-duan/</id>
        <link href="https://oldcamel.run/post/40-xin-de-kai-duan/">
        </link>
        <updated>2021-05-31T08:22:46.000Z</updated>
        <content type="html"><![CDATA[<p>又又又又开始搭建新框架了,这次开搞多租户云服务。</p>
<table>
<thead>
<tr>
<th>初步计划列表</th>
<th>完成情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>mars-spring-boot-starter  多数据源  jpa+mybatis</td>
<td>☑️</td>
</tr>
<tr>
<td>mars-spring-boot-starter  mybatis 换成mybatisplus</td>
<td>☑️</td>
</tr>
<tr>
<td>mars-spring-boot-starter  liquibase初步集成（多数据源在启动时刷新库）</td>
<td>☑️</td>
</tr>
<tr>
<td>认证中心 升级 2.5.0  spring-cloud-oauth2换成 spring-security  oauth2</td>
<td>☑️</td>
</tr>
<tr>
<td>认证中心 jpa在pgsql里运行, 调试功能</td>
<td>☑️</td>
</tr>
<tr>
<td>mars-spring-boot-starter  添加通用设置+工具类+pom依赖（依赖项目pom精简）</td>
<td>☑️</td>
</tr>
<tr>
<td>mars-archetype maven模板项目重新修改</td>
<td>☑️</td>
</tr>
</tbody>
</table>
<h2 id="mars-spring-boot-starter-多数据源-jpamybatis">mars-spring-boot-starter  多数据源  jpa+mybatis</h2>
<p>多租户系统,数据库按租户区分数据源。计划每个租户单独数据源部署，所以先搞个启动器配置多数据源。<br>
多数据源实现:继承AbstractRoutingDataSource，重写determineCurrentLookupKey方法 返回自定义的key。这个key 用拦截器在请求头里获取用户的租户值放到一个线程变量里。</p>
<ul>
<li>拦截器</li>
</ul>
<pre><code class="language-java">public class TenantInterceptor implements HandlerInterceptor {
    final String X_TENANT_ID = &quot;X_TenantID&quot;;
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        final String tenantId = request.getHeader(X_TENANT_ID);
        if (tenantId != null) {
            DynamicDataSourceContextHolder.setDataSourceKey(tenantId);
        }
        return true;
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        DynamicDataSourceContextHolder.clearDataSourceKey();
    }
}

@Configuration
public class TenantConfig implements WebMvcConfigurer {
    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        //指定拦截器，指定拦截路径
        registry.addInterceptor(new TenantInterceptor()).addPathPatterns(&quot;/**&quot;);
    }
}

</code></pre>
<ul>
<li>线程变量</li>
</ul>
<pre><code class="language-java">public class DynamicDataSourceContextHolder {
  private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;() {
      /**
       * 将 master 数据源的 key作为默认数据源的 key
       */
      @Override
      protected String initialValue() {
          return &quot;master&quot;;
      }
  };

  /**
   * 数据源的 key集合，用于切换时判断数据源是否存在
   */
  public static Set&lt;Object&gt; dataSourceKeys = new HashSet&lt;&gt;();

  /**
   * 切换数据源
   * @param key  数据源
   */
  public static void setDataSourceKey(String key) {
      if (StringUtils.isNotBlank(key)) {
          contextHolder.set(key);
      }
  }

  /**
   * 获取数据源
   * @return
   */
  public static String getDataSourceKey() {
      return contextHolder.get();
  }

  /**
   * 重置数据源
   */
  public static void clearDataSourceKey() {
      contextHolder.remove();
  }

  /**
   * 判断是否包含数据源
   * @param key   数据源
   * @return
   */
  public static boolean containDataSourceKey(String key) {
      return dataSourceKeys.contains(key);
  }

  /**
   * 添加数据源Keys
   * @param keys
   * @return
   */
  public static boolean addDataSourceKeys(Collection&lt;? extends Object&gt; keys) {
      return dataSourceKeys.addAll(keys);
  }
}
</code></pre>
<ul>
<li>配置数据源</li>
</ul>
<pre><code class="language-java">
 @Bean(&quot;master&quot;)
   @ConfigurationProperties(prefix = &quot;spring.datasource.hikari&quot;)
   public DataSource master(){
       HikariDataSource build = (HikariDataSource)DataSourceBuilder.create().build();
       build.setTransactionIsolation(&quot;TRANSACTION_READ_COMMITTED&quot;);
       return build;
   }
   @Bean
   @Primary
   public DataSource dataSource(){
       DynamicDataSource dynamicDataSource = new DynamicDataSource();
       HashMap&lt;Object, Object&gt; dataSourceMap = new HashMap&lt;&gt;();
       dataSourceMap.put(&quot;master&quot;,master());
       dynamicDataSource.setDefaultDataSource(master());
       dynamicDataSource.setDataSources(dataSourceMap);
       dynamicDataSource.afterPropertiesSet();
       return  dynamicDataSource;
   }

</code></pre>
<ul>
<li>多数据源读取</li>
</ul>
<pre><code class="language-java">@Data
public class DynamicDataSource  extends AbstractRoutingDataSource {
  private final Map&lt;Object, Object&gt; tenantDataSources = new ConcurrentHashMap&lt;&gt;();

  @Override
  protected Object determineCurrentLookupKey() {
      return DynamicDataSourceContextHolder.getDataSourceKey();
  }


  public void setDefaultDataSource(Object defaultDataSource) {
      super.setDefaultTargetDataSource(defaultDataSource);
  }

  public void setDataSources(Map&lt;Object, Object&gt; dataSources) {
      tenantDataSources.putAll(dataSources);
      super.setTargetDataSources(tenantDataSources);
      super.afterPropertiesSet();
      DynamicDataSourceContextHolder.addDataSourceKeys(dataSources.keySet());
  }

}
</code></pre>
<ul>
<li>创建租户表</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://oldcamel.run/post-images/1622451428396.png" alt="" loading="lazy"></figure>
<ul>
<li>写ApplicationRunner在项目启动完成后添加多租户数据源</li>
</ul>
<pre><code class="language-java">  public class DynamicDataSourceInit implements ApplicationRunner {
    @Autowired
    DynamicDataSource dataSource;
    @Override
    public void run(ApplicationArguments args) throws Exception {
        HikariDataSource hikariDataSource = (HikariDataSource) SpringContextUtils.getBean(&quot;master&quot;);
        Map&lt;Object, Object&gt; resolvedDataSources =new HashMap&lt;&gt;();
        Connection connection = hikariDataSource.getConnection();
        Statement statement = connection.createStatement();
        ResultSet resultSet = statement.executeQuery(&quot;select tenant_id   \&quot;tenantId\&quot;,tenant_name \&quot;tenantName\&quot;,datasource_url \&quot;datasourceUrl\&quot;,datasource_username \&quot;datasourceUsername\&quot;,datasource_password \&quot;datasourcePassword\&quot;,datasource_driver \&quot;datasourceDriver\&quot; from tenant where status=1&quot;);
        List&lt;Tenant&gt; tenants = (ArrayList&lt;Tenant&gt;) this.populate(resultSet, Tenant.class);
        for (Tenant tenant : tenants) {
            HikariDataSource dataSource = new HikariDataSource();
            dataSource.setDriverClassName(tenant.getDatasourceDriver());
            dataSource.setJdbcUrl(tenant.getDatasourceUrl());
            dataSource.setUsername(tenant.getDatasourceUsername());
            dataSource.setPassword(tenant.getDatasourcePassword());
            dataSource.setConnectionTestQuery(&quot;SELECT 1&quot;);
            dataSource.setTransactionIsolation(&quot;TRANSACTION_READ_COMMITTED&quot;);
            dataSource.setDataSourceProperties(hikariDataSource.getDataSourceProperties());
            resolvedDataSources.put(tenant.getTenantId(), dataSource);
        }
        dataSource.setDataSources(resolvedDataSources);
        dataSource.afterPropertiesSet();
        connection.close();
    }
    private    List populate(ResultSet rs , Class clazz) throws SQLException, InstantiationException, IllegalAccessException{
        //结果集的元素对象
        ResultSetMetaData rsmd = rs.getMetaData();
        //获取结果集的元素个数
        int colCount = rsmd.getColumnCount();
        //返回结果的列表集合
        List list = new ArrayList();
        //业务对象的属性数组
        Field[] fields = clazz.getDeclaredFields();
        while(rs.next()){//对每一条记录进行操作
            Object obj = clazz.newInstance();//构造业务对象实体
            //将每一个字段取出进行赋值
            for(int i = 1;i&lt;=colCount;i++){
                Object value = rs.getObject(i);
                //寻找该列对应的对象属性
                for(int j=0;j&lt;fields.length;j++){
                    Field f = fields[j];
                    //如果匹配进行赋值
                    if(f.getName().equalsIgnoreCase(rsmd.getColumnName(i))){
                        boolean flag = f.isAccessible();
                        f.setAccessible(true);
                        f.set(obj, value);
                        f.setAccessible(flag);
                    }
                }
            }
            list.add(obj);
        }
        return list;
    }
}
</code></pre>
<h1 id="mars-spring-boot-starter-mybatis-换成mybatisplus">mars-spring-boot-starter  mybatis 换成mybatisplus</h1>
<p>因为部分项目组用了mybatisplus,在启动器里把mybatis升级成mybatisplus，里面分页插件 采用 pagehelper+mybatisplus自带分页 并存的方式。</p>
<ul>
<li>添加依赖</li>
</ul>
<pre><code class="language-xml"> &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.4.3&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
            &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;1.3.0&lt;/version&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
                    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency
</code></pre>
<ul>
<li>mybatisplus+ 分页 配置</li>
</ul>
<pre><code class="language-java">    @Bean
    @ConfigurationProperties(prefix = &quot;pagehelper&quot;)
    public Properties pageHelperProperties() {
        return new Properties();
    }
   @Bean
    public MybatisSqlSessionFactoryBean sqlSessionFactoryBean() throws Exception {
        MybatisSqlSessionFactoryBean sessionFactory = new MybatisSqlSessionFactoryBean();
        Interceptor[] plugins = new Interceptor[2];
        plugins[0] = mybatisPlusInterceptor();
        plugins[1] = pageHelperInterceptor();
        sessionFactory.setPlugins(plugins);
        sessionFactory.setDataSource(dataSource());
        PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();
        sessionFactory.setMapperLocations(resolver.getResources(&quot;classpath*:**/*Mapper.xml&quot;));
        return sessionFactory;
    }
    @Bean
    public PlatformTransactionManager transactionManager() {
        return new DataSourceTransactionManager(dataSource());
    }
    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor() {
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        PaginationInnerInterceptor paginationInnerInterceptor = new PaginationInnerInterceptor(DbType.POSTGRE_SQL);
        BlockAttackInnerInterceptor blockAttackInnerInterceptor = new BlockAttackInnerInterceptor();
        //分页插件
        interceptor.addInnerInterceptor(paginationInnerInterceptor);
        //防止全表更新与删除
        interceptor.addInnerInterceptor(blockAttackInnerInterceptor);
        return interceptor;
    }
    @Bean
    public PageInterceptor pageHelperInterceptor() {
        PageInterceptor interceptor = new PageInterceptor();
        interceptor.setProperties(this.pageHelperProperties());
        return interceptor;
    }
</code></pre>
<h1 id="mars-spring-boot-starter-liquibase初步集成多数据源在启动时刷新库">mars-spring-boot-starter  liquibase初步集成（多数据源在启动时刷新库)</h1>
<ul>
<li>CustomLiquibaseProperties</li>
</ul>
<pre><code class="language-java">public class CustomLiquibaseProperties extends LiquibaseProperties {
    /**
     * 是否是除master数据库外其他数据库同步更新
     */
    private boolean global=true;
    public boolean isGlobal() {
        return global;
    }
    public void setGlobal(boolean global) {
        this.global = global;
    }
}


</code></pre>
<p>项目配置文件配置</p>
<pre><code class="language-properties">spring.liquibase.enabled=true
spring.liquibase.default-schema=public
spring.liquibase.change-log=classpath:db/changelog/db.changelog-master.xml
spring.liquibase.database-change-log-table=LIQUIBASE_CHANGELOG_TEST
spring.liquibase.database-change-log-lock-table=LIQUIBASE_CHANGELOG_LOCK_TEST

</code></pre>
<ul>
<li>
<p>LiquibaseConfig</p>
<pre><code class="language-java"></code></pre>
</li>
</ul>
<p>public class LiquibaseConfig {<br>
private CustomLiquibaseProperties properties;<br>
@Bean<br>
@DependsOn(&quot;dataSource&quot;)<br>
public DataSourceSpringLiquibase springLiquibase(DynamicDataSource dataSource) {<br>
DataSourceSpringLiquibase dataSourceSpringLiquibase = new DataSourceSpringLiquibase(dataSource,properties);<br>
return dataSourceSpringLiquibase;<br>
}<br>
}</p>
<pre><code>
- DataSourceSpringLiquibase

```java

public class DataSourceSpringLiquibase implements ResourceLoaderAware {
    public static final String DISABLED_MESSAGE = &quot;Liquibase is disabled&quot;;
    public static final String STARTING_SYNC_MESSAGE = &quot;Starting Liquibase synchronously&quot;;
    public static final String STARTED_MESSAGE = &quot;Liquibase has updated your database in {} ms&quot;;
    public static final String EXCEPTION_MESSAGE = &quot;Liquibase could not start correctly, your database is NOT ready: &quot; + &quot;{}&quot;;
    public static final long SLOWNESS_THRESHOLD = 5; // seconds
    public static final String SLOWNESS_MESSAGE = &quot;Warning, Liquibase took more than {} seconds to start up!&quot;;
    private DynamicDataSource dynamicDataSource;
    private CustomLiquibaseProperties customLiquibaseProperties;
    private ResourceLoader resourceLoader;


    public DataSourceSpringLiquibase(DynamicDataSource dynamicDataSource, CustomLiquibaseProperties customLiquibaseProperties) {
        this.dynamicDataSource = dynamicDataSource;
        this.customLiquibaseProperties = customLiquibaseProperties;
    }
    public void run() throws Exception {
        log.info(&quot;DataSources based multiTenancy enabled&quot;);
        runOnAllDataSources();
    }
    private void runOnAllDataSources() throws Exception {
        Map&lt;Object, DataSource&gt; resolvedDataSources = this.dynamicDataSource.getResolvedDataSources();
        for (Map.Entry&lt;Object, DataSource&gt; entry : resolvedDataSources.entrySet()) {
            Object tenant = entry.getKey();
            String t=(String) tenant;
            if(customLiquibaseProperties.isGlobal()){
                if(t.equals(&quot;master&quot;)){
                    continue;
                }
            }else{
                if(!t.equals(&quot;master&quot;)){
                    continue;
                }
            }
            DataSource dataSource = entry.getValue();
            init(tenant, dataSource);
        }

    }

    private void init(Object tenant, DataSource dataSource) throws LiquibaseException {
        log.info(&quot;Initializing Liquibase for data source &quot; + tenant);
        SpringLiquibase liquibase = getSpringLiquibase(dataSource, customLiquibaseProperties);
        try {
            log.warn(STARTING_SYNC_MESSAGE);
            initDb(liquibase);
        } catch (LiquibaseException e) {
            log.error(EXCEPTION_MESSAGE, e.getMessage(), e);
            throw e;
        }
        log.info(&quot;Liquibase run for data source &quot; + tenant);
    }

    private void initDb(SpringLiquibase liquibase) throws LiquibaseException {
        StopWatch watch = new StopWatch();
        watch.start();
        liquibase.afterPropertiesSet();
        watch.stop();
        log.debug(STARTED_MESSAGE, watch.getTotalTimeMillis());
        if (watch.getTotalTimeMillis() &gt; SLOWNESS_THRESHOLD * 1000L) {
            log.warn(SLOWNESS_MESSAGE, SLOWNESS_THRESHOLD);
        }
    }


    private SpringLiquibase getSpringLiquibase(DataSource dataSource, CustomLiquibaseProperties properties) {
        SpringLiquibase liquibase = new SpringLiquibase();
        liquibase.setChangeLog(properties.getChangeLog());
        liquibase.setChangeLogParameters(properties.getParameters());
        liquibase.setContexts(properties.getContexts());
        liquibase.setLabels(properties.getLabels());
        liquibase.setDropFirst(properties.isDropFirst());
        liquibase.setShouldRun(properties.isEnabled());
        liquibase.setRollbackFile(properties.getRollbackFile());
        liquibase.setResourceLoader(resourceLoader);
        liquibase.setDataSource(dataSource);
        liquibase.setDefaultSchema(properties.getDefaultSchema());
        liquibase.setLiquibaseSchema(properties.getLiquibaseSchema());
        liquibase.setLiquibaseTablespace(properties.getLiquibaseTablespace());
        liquibase.setDatabaseChangeLogTable(properties.getDatabaseChangeLogTable());
        liquibase.setDatabaseChangeLogLockTable(properties.getDatabaseChangeLogLockTable());
        return liquibase;
    }
}

</code></pre>
<ul>
<li>修改项目ApplicationRunnner<br>
run方法最后添加</li>
</ul>
<pre><code class="language-java">//刷新数据库
 dataSourceSpringLiquibase.run(); 
</code></pre>
<h1 id="项目liquibase配置">项目liquibase配置</h1>
<h2 id="maven配置">maven配置</h2>
<pre><code class="language-xml">&lt;plugin&gt;
               &lt;groupId&gt;org.liquibase&lt;/groupId&gt;
               &lt;artifactId&gt;liquibase-maven-plugin&lt;/artifactId&gt;
               &lt;version&gt;4.3.5&lt;/version&gt;
               &lt;configuration&gt;
                   &lt;!-- properties文件路径，该文件记录了数据库连接信息等--&gt;
                   &lt;propertyFile&gt;src/main/resources/liquibase.properties&lt;/propertyFile&gt;
                   &lt;!-- 是否每次都重新加载properties --&gt;
                   &lt;propertyFileWillOverride&gt;true&lt;/propertyFileWillOverride&gt;
                   &lt;!-- 输出文件的编码 --&gt;
                   &lt;outputFileEncoding&gt;UTF-8&lt;/outputFileEncoding&gt;
                   &lt;!-- 是否需要弹出确认框 --&gt;
                   &lt;promptOnNonLocalDatabase&gt;false&lt;/promptOnNonLocalDatabase&gt;
                   &lt;!-- diff 输出文件目录 这个文件夹被git 忽略了--&gt;
                   &lt;diffChangeLogFile&gt;
                       src/main/resources/liquibase/diff/liquibase-diff-${maven.build.timestamp}-changeLog.xml
                   &lt;/diffChangeLogFile&gt;
                   &lt;!-- 日志界别 --&gt;
                   &lt;logging&gt;debug&lt;/logging&gt;
               &lt;/configuration&gt;
               &lt;dependencies&gt;
                   &lt;dependency&gt;
                       &lt;groupId&gt;org.liquibase.ext&lt;/groupId&gt;
                       &lt;artifactId&gt;liquibase-hibernate5&lt;/artifactId&gt;
                       &lt;version&gt;4.3.5&lt;/version&gt;
                   &lt;/dependency&gt;
                   &lt;dependency&gt;
                       &lt;groupId&gt;com.yunzainfo.cloud&lt;/groupId&gt;
                       &lt;artifactId&gt;mars-spring-boot-starter&lt;/artifactId&gt;
                       &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
                   &lt;/dependency&gt;
               &lt;/dependencies&gt;
           &lt;/plugin&gt;
</code></pre>
<h2 id="liquibase配置">liquibase配置</h2>
<pre><code>
#项目的表所在的schema
defaultSchemaName=spauth
#liquibase的表所在的schema
changelogSchemaName=public
#下面两个配置注意修改后缀为项目简称，必须注意不能与已有的表重名
databaseChangeLogTableName=LIQUIBASE_CHANGELOG_AUTH
databaseChangeLogLockTableName=LIQUIBASE_CHANGELOG_LOCK_AUTH
#变更数据集配置文件,一般不用修改
changeLogFile=src/main/resources/liquibase/db.changelog-master.xml
#要生成的初始化数据集文件。只在项目初始化的时候用
outputChangeLogFile=src/main/resources/liquibase/changes/init1.changelog.xml
#数据库连接
url: jdbc:postgresql://192.168.xxx.xxx:5434/mars
#用户名
username=postgres
#密码
password=xxxxxx
#驱动
driver=org.postgresql.Driver
#用jpa的项目把报名修改成项目里的entity的包路径,可用diff命令，生成diff文件,用来创建增量changeset
referenceUrl=hibernate:spring:com.yunzainfo.cloud.auth.entity?\
   dialect=org.hibernate.dialect.PostgreSQLDialect&amp;\
   hibernate.physical_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy&amp;\
   hibernate.implicit_naming_strategy=org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy
#比较类型, 在用jpa的diff时，用diffTypes=tables,columns,在项目初始化时用下面那个
#diffTypes=tables,columns
diffTypes=tables,functions,views,columns,indexes,foreignkeys,primarykeys,uniqueconstraints,data


</code></pre>
<h2 id="spring配置">spring配置</h2>
<pre><code>liquibase:
  change-log: classpath:liquibase/db.changelog-master.xml
  enabled: true
  database-change-log-table: LIQUIBASE_CHANGELOG_AUTH
  database-change-log-lock-table: LIQUIBASE_CHANGELOG_LOCK_AUTH
  liquibase-schema: public
  default-schema: spauth
</code></pre>
<h1 id="oauth2-多租户重点配置项">oauth2 多租户重点配置项</h1>
<h2 id="requestwrapper-修改request参数header-装饰类">RequestWrapper 修改request参数+header 装饰类</h2>
<pre><code class="language-java">
/**
 * Created by IntelliJ IDEA
 * TODO: TODO
 *
 * @author: 徐成
 * Date: 2021/6/8
 * Time: 5:20 下午
 * Email: old_camel@163.com
 */
public class RequestWrapper extends HttpServletRequestWrapper {
    private static final Logger log = LoggerFactory.getLogger(RequestWrapper.class);
    private String mBody;
    private Map&lt;String, String[]&gt; parameterMap; // 所有参数的Map集合
    public RequestWrapper(HttpServletRequest request) {
        super(request);
        this.mBody = this.getBody(request);
        parameterMap = request.getParameterMap();

    }

    /**
     * 获取所有参数名
     *
     * @return 返回所有参数名
     */
    @Override
    public Enumeration&lt;String&gt; getParameterNames() {
        Vector&lt;String&gt; vector = new Vector&lt;String&gt;(parameterMap.keySet());
        return vector.elements();
    }

    /**
     * 获取指定参数名的值，如果有重复的参数名，则返回第一个的值 接收一般变量 ，如text类型
     *
     * @param name 指定参数名
     * @return 指定参数名的值
     */
    @Override
    public String getParameter(String name) {
        String[] results = parameterMap.get(name);
        return results[0];
    }


    /**
     * 获取指定参数名的所有值的数组，如：checkbox的所有数据
     * 接收数组变量 ，如checkobx类型
     */
    @Override
    public String[] getParameterValues(String name) {
        return parameterMap.get(name);
    }

    @Override
    public Map&lt;String, String[]&gt; getParameterMap() {
        return parameterMap;
    }

    public void setParameterMap(Map&lt;String, String[]&gt; parameterMap) {
        this.parameterMap = parameterMap;
    }

    public static String convertStreamToString(InputStream is) {
        BufferedReader reader = new BufferedReader(new InputStreamReader(is));
        StringBuilder sb = new StringBuilder();

        try {
            String line;
            try {
                while ((line = reader.readLine()) != null) {
                    sb.append(line + &quot;\n&quot;);
                }
            } catch (IOException var13) {
                log.error(&quot;IOException&quot;, var13);
            }
        } finally {
            try {
                is.close();
            } catch (IOException var12) {
                log.error(&quot;IOException&quot;, var12);
            }

        }

        return sb.toString();
    }

    private String getBody(HttpServletRequest request) {
        try {
            return convertStreamToString(request.getInputStream());
        } catch (IOException var3) {
            log.debug(var3.getMessage());
            throw new YzCommonException(var3.getMessage());
        }
    }

    public String getBody() {
        return this.mBody;
    }

    @Override

    public BufferedReader getReader() throws IOException {
        return new BufferedReader(new InputStreamReader(this.getInputStream()));
    }

    @Override
    public ServletInputStream getInputStream() throws IOException {
        final ByteArrayInputStream bais = new ByteArrayInputStream(this.mBody.getBytes(Charset.defaultCharset()));
        return new ServletInputStream() {
            @Override
            public boolean isFinished() {
                return false;
            }

            @Override
            public boolean isReady() {
                return false;
            }

            @Override

            public void setReadListener(ReadListener readListener) {
            }

            @Override
            public int read() throws IOException {
                return bais.read();
            }
        };
    }
}
</code></pre>
<h2 id="yzjdbcclientdetailsservice-的自定义jdbctemplete类">YzJdbcClientDetailsService 的自定义JdbcTemplete类</h2>
<p>修改execute方法，用来切换数据源</p>
<pre><code class="language-java"> @Nullable
    private &lt;T&gt; T execute(PreparedStatementCreator psc, PreparedStatementCallback&lt;T&gt; action, boolean closeResources)
            throws DataAccessException {
        if(&quot;master&quot;.equals(DynamicDataSourceContextHolder.getDataSourceKey())) {
            HttpServletRequest request = ((ServletRequestAttributes) Objects.requireNonNull(RequestContextHolder.getRequestAttributes())).getRequest();
            final String tenantId = request.getHeader(X_TENANT_ID);
            if (tenantId != null) {
                DynamicDataSourceContextHolder.setDataSourceKey(tenantId);
            }

....

</code></pre>
<h2 id="用户登录拦截器-tenantuserloginfilter">用户登录拦截器 TenantUserLoginFilter</h2>
<p>登录只传用户名密码 获取token</p>
<pre><code class="language-java">@Slf4j
@WebFilter(urlPatterns = &quot;/user/login&quot;, filterName = &quot;tenantUserLoginFilter&quot;)
public class TenantUserLoginFilter extends GenericFilterBean {

    private HashMap&lt;String, String[]&gt; webapp = new HashMap&lt;String, String[]&gt;() {
        {
            put(&quot;grant_type&quot;, new String[]{&quot;password&quot;});
            put(&quot;client_id&quot;, new String[]{&quot;webapp&quot;});
            put(&quot;scope&quot;, new String[]{&quot;webapp&quot;});
            put(&quot;client_secret&quot;, new String[]{&quot;123456&quot;});
        }
    };

    @Autowired
    UserService userService;

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        ParameterMap&lt;String, String[]&gt; parameterMap = (ParameterMap&lt;String, String[]&gt;) servletRequest.getParameterMap();
        String username = parameterMap.get(&quot;username&quot;)[0];
        TenantUser user = userService.getById(username);
        if (user == null) {
            final HttpServletResponse response = (HttpServletResponse) servletResponse;
            response.setStatus(HttpServletResponse.SC_BAD_REQUEST);
            response.setContentType(MediaType.APPLICATION_JSON_VALUE);
            ReturnEntity&lt;Object&gt; build = ReturnEntity.builder().errorMessage(&quot;用户不存在!&quot;).build();
            response.getWriter().write(JSON.toJSONString(build));
            response.getWriter().flush();
            return;
        }
        RequestWrapper requestWrapper = new RequestWrapper((HttpServletRequest) servletRequest) {
            /**
             * 当调用request.getHeader(&quot;token&quot;)时，则获取请求参数中token值并当做Header的值返回 * @param name
             * @return
             */
            @Override
            public String getHeader(String name) {
                // 先从原本的Request中获取头，如果为空且名字为token，则从参数中查找并返回
                String superHeader = super.getHeader(name);
                if (&quot;X_TenantID&quot;.equals(name) &amp;&amp; StringUtils.isEmpty(superHeader)) {
                    return user.getTenantId();
                }
                return superHeader;
            }
        };
        Map&lt;String, String[]&gt; map = new HashMap&lt;&gt;(requestWrapper.getParameterMap());
        map.putAll(webapp);
        requestWrapper.setParameterMap(map);
        log.info(&quot;TenantUserLoginFilter 执行完成&quot;);
        filterChain.doFilter(requestWrapper, servletResponse);
    }
}
</code></pre>
<h2 id="登录接口">登录接口</h2>
<p>方法里直接转发到/oauth/token方法。注意这里的request是在过滤器里修改过的封装类。</p>
<pre><code class="language-java">@Autowired
    UserService userService;
    @RequestMapping(value = &quot;/user/login&quot;,method = RequestMethod.POST)
    public void loginOauth2( HttpServletRequest request,HttpServletResponse response) throws ServletException, IOException {
        request.getRequestDispatcher(&quot;/oauth/token&quot;).forward(request,response);

</code></pre>
<h2 id="覆盖-link-tokenendpoint做客户端的认证">覆盖 {@link TokenEndpoint}，做客户端的认证</h2>
<pre><code class="language-java"> @Autowired
    private TokenEndpoint tokenEndpoint;
    @Autowired
    AuthorizationServerSecurityConfiguration authorizationServerSecurityConfiguration;

    @RequestMapping(value = &quot;/oauth/token&quot;, method = {RequestMethod.GET, RequestMethod.POST})
    @ApiOperation(value = &quot;获取token&quot;)
    public ResponseEntity&lt;OAuth2AccessToken&gt; getAccessToken(Principal principal, @RequestParam Map&lt;String, String&gt; parameters, HttpServletRequest request) throws HttpRequestMethodNotSupportedException {
        if (!(principal instanceof Authentication)) {
            String clientId = parameters.get(&quot;client_id&quot;);
            String clientSecret = parameters.get(&quot;client_secret&quot;);
            if (clientId == null) {
                throw new BadCredentialsException(&quot;No client credentials presented&quot;);
            }
            if (clientSecret == null) {
                clientSecret = &quot;&quot;;
            }
            clientId = clientId.trim();
            UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(clientId,
                    clientSecret);
            Field httpField = ReflectUtil.getField(AuthorizationServerSecurityConfiguration.class, &quot;http&quot;);
            HttpSecurity http = (HttpSecurity) ReflectUtil.getFieldValue(authorizationServerSecurityConfiguration, httpField);
            AuthenticationManager authenticationManager = http.getSharedObject(AuthenticationManager.class);
            Authentication authenticate = authenticationManager.authenticate(authRequest);
            principal = authenticate;

        }

        return tokenEndpoint.postAccessToken(principal, parameters);
    }

</code></pre>
<h1 id="结束">结束</h1>
<p>升级搞定</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kubernetes 问题处理记录]]></title>
        <id>https://oldcamel.run/post/kubernetes-wen-ti-chu-li-ji-lu/</id>
        <link href="https://oldcamel.run/post/kubernetes-wen-ti-chu-li-ji-lu/">
        </link>
        <updated>2021-05-26T01:28:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-强制删除namespace">1、强制删除namespace</h1>
<p>kubectl get namespace rook-ceph -o json &gt; rook-ceph.json<br>
vim rook-ceph.json<br>
删除spec中的内容<br>
<code>&quot;spec&quot;: { }</code><br>
开启kube-proxy   kubectl proxy</p>
<p>另开一个ssh登录master，执行<br>
<code>curl -k -H &quot;Content-Type: application/json&quot; -X PUT --data-binary @rook-ceph.json http://127.0.0.1:8001/api/v1/namespaces/rook-ceph/finalize</code><br>
操作完成👌</p>
<h1 id="2-kubectl-get-pod-获取不到资源">2、kubectl get pod 获取不到资源</h1>
<p>大概率是节点网络插件出现了问题。重启istiod 服务尝试将其运行在不同的节点上试下</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flink Sql 实现CDC数据实时同步特殊处理]]></title>
        <id>https://oldcamel.run/post/flink-sql-shi-xian-cdc-shu-ju-shi-shi-tong-bu-te-shu-chu-li/</id>
        <link href="https://oldcamel.run/post/flink-sql-shi-xian-cdc-shu-ju-shi-shi-tong-bu-te-shu-chu-li/">
        </link>
        <updated>2021-04-15T01:06:21.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1-decimal-类型在kafka中解析为乱码">1、decimal 类型在kafka中解析为乱码</h1>
<p>kafka connect 插件设置 &quot;decimal.handling.mode&quot;: &quot;string&quot; 属性。将decimal解析为字符串</p>
<p>sql语句中将字符串转换为数字 用CAST(字段名称) AS INT) 函数  INT可根据不同类型的数字替换为不同的目标类型（DECIMAL(10,4) BIGINT 等）</p>
<h1 id="2-日期处理">2、日期处理</h1>
<p>kafka中人日期类型会解析成时间戳，可用TO_TIMESTAMP + FROM_UNIXTIME做转换，注意处理时区问题</p>
<p>oracle日期类型处理精度+时区：</p>
<pre><code>CREATED_DATETS AS TO_TIMESTAMP(FROM_UNIXTIME(CREATED_DATE/1000/1000-8 * 60 * 60, 'yyyy-MM-dd HH:mm:ss')),
</code></pre>
<p>其他数据库日期类型只处理日期</p>
<pre><code>FDateTS AS TO_TIMESTAMP(FROM_UNIXTIME((FDate-8 * 60 * 60 * 1000) / 1000, 'yyyy-MM-dd HH:mm:ss'))
</code></pre>
<h1 id="3-cdc数据插入设置主键">3、cdc数据插入设置主键</h1>
<pre><code>PRIMARY KEY (AAA,BBB) NOT ENFORCED
</code></pre>
<h1 id="4-kafka-sink-sasl-connect插件设置认证">4、kafka sink sasl connect插件设置认证</h1>
<pre><code>&quot;database.history.producer.sasl.mechanism&quot;: &quot;PLAIN&quot;,
&quot;database.history.producer.sasl.jaas.config&quot;: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;密码\&quot;;&quot;,
&quot;database.history.producer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
&quot;database.history.consumer.sasl.jaas.config&quot;: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;密码\&quot;;&quot;,
&quot;database.history.consumer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
&quot;database.history.consumer.sasl.mechanism&quot;: &quot;PLAIN&quot;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka实现oracle的CDC数据实时变更]]></title>
        <id>https://oldcamel.run/post/kafka-shi-xian-oracle-de-cdc-shu-ju-shi-shi-bian-geng/</id>
        <link href="https://oldcamel.run/post/kafka-shi-xian-oracle-de-cdc-shu-ju-shi-shi-bian-geng/">
        </link>
        <updated>2021-04-14T06:02:54.000Z</updated>
        <content type="html"><![CDATA[<h1 id="使用工具-debezium-oracle-connectororacle-logminer">使用工具  debezium-oracle-connector,oracle-LogMiner</h1>
<h2 id="1-oracle-设置">1、oracle 设置</h2>
<h3 id="开启归档模式">开启归档模式</h3>
<pre><code class="language-sqlplus">alter system set db_recovery_file_dest_size = 10G;
alter system set db_recovery_file_dest = '/home/oracle/oradta/recovery_area' scope=spfile;
shutdown immediate
startup mount
alter database archivelog;
alter database open;
archive log list
exit;

ALTER DATABASE ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;

</code></pre>
<h4 id="创建用户">创建用户</h4>
<pre><code>CREATE USER myuser IDENTIFIED BY dbz
   DEFAULT TABLESPACE 命名空间
   QUOTA UNLIMITED ON 命名空间
</code></pre>
<h4 id="授权">授权</h4>
<pre><code>GRANT CREATE SESSION TO myuser;
GRANT CREATE TABLE TO myuser;
GRANT CREATE SEQUENCE TO myuser;
GRANT CREATE TRIGGER TO myuser;
GRANT CREATE SESSION TO myuser;
GRANT SELECT ON V_$DATABASE to myuser;
GRANT FLASHBACK ANY TABLE TO myuser;
GRANT SELECT ANY TABLE TO myuser;
GRANT SELECT_CATALOG_ROLE TO myuser;
GRANT EXECUTE_CATALOG_ROLE TO myuser;
GRANT SELECT ANY TRANSACTION TO myuser;
GRANT CREATE TABLE TO myuser;
GRANT LOCK ANY TABLE TO myuser;
GRANT ALTER ANY TABLE TO myuser;
GRANT CREATE SEQUENCE TO myuser;
GRANT EXECUTE ON DBMS_LOGMNR TO myuser;
GRANT EXECUTE ON DBMS_LOGMNR_D TO myuser;
GRANT SELECT ON V_$LOG TO myuser;
GRANT SELECT ON V_$LOG_HISTORY TO myuser;
GRANT SELECT ON V_$LOGMNR_LOGS TO myuser;
GRANT SELECT ON V_$LOGMNR_CONTENTS TO myuser;
GRANT SELECT ON V_$LOGMNR_PARAMETERS TO myuser;
GRANT SELECT ON V_$LOGFILE TO myuser;
GRANT SELECT ON V_$ARCHIVED_LOG TO myuser;
GRANT SELECT ON V_$ARCHIVE_DEST_STATUS TO myuser;
GRANT SELECT ON SYSTEM.LOGMNR_COL$ TO myuser;
GRANT SELECT ON SYSTEM.LOGMNR_OBJ$ TO myuser;
GRANT SELECT ON SYSTEM.LOGMNR_USER$ TO myuser;
GRANT SELECT ON SYSTEM.LOGMNR_UID$ TO myuser;
</code></pre>
<h2 id="oracle客户端设置">oracle客户端设置</h2>
<h3 id="下载">下载</h3>
<pre><code>wget &quot;https://download.oracle.com/otn_software/linux/instantclient/19600/instantclient-basiclite-linux.x64-19.6.0.0.0dbru.zip&quot; -O /tmp/ic.zip；
unzip /tmp/ic.zip -d  自定义目录
</code></pre>
<h3 id="环境变量">环境变量</h3>
<p>设置LD_LIBRARY_PATH 指向 自定义目录</p>
<h2 id="kafaka-connect-插件设置">kafaka connect 插件设置</h2>
<h3 id="下载-2">下载</h3>
<pre><code>wget &quot;https://oss.sonatype.org/service/local/artifact/maven/redirect?r=snapshots&amp;g=io.debezium&amp;a=debezium-connector-oracle&amp;v=LATEST&amp;c=plugin&amp;e=tar.gz&quot; -O /tmp/dbz-ora.tgz；
tar -xvf /tmp/dbz-ora.tgz --directory  kafaka 插件目录
</code></pre>
<h3 id="添加-ojdbc-jar到插件目录">添加 ojdbc jar到插件目录</h3>
<pre><code>      curl https://maven.xwiki.org/externals/com/oracle/jdbc/ojdbc8/12.2.0.1/ojdbc8-12.2.0.1.jar -o ojdbc8-12.2.0.1.jar
</code></pre>
<h2 id="创建kafka-connect">创建kafka connect</h2>
<pre><code>curl --location --request POST 'http://localhost:8083/connectors' \
--header 'Content-Type: application/json' \
--data-raw '{
   &quot;name&quot;: &quot;name&quot;,
   &quot;config&quot;: {
       &quot;connector.class&quot; : &quot;io.debezium.connector.oracle.OracleConnector&quot;,
       &quot;tasks.max&quot; : &quot;1&quot;,
       &quot;database.server.name&quot; : &quot;topic&quot;,
       &quot;database.hostname&quot; : &quot;database_host&quot;,
       &quot;database.port&quot; : &quot;1521&quot;,
       &quot;database.user&quot; : &quot;myuser&quot;,
       &quot;database.password&quot; : &quot;dbz&quot;,
       &quot;database.dbname&quot; : &quot;orcl&quot;,
       &quot;database.tablename.case.insensitive&quot;: &quot;true&quot;,
       &quot;database.history.kafka.bootstrap.servers&quot; : &quot;localhost:9092&quot;,
       &quot;database.history.kafka.topic&quot;: &quot;name-h&quot;,
       &quot;table.include.list&quot;:&quot;AAA.BBB,CCC.DDD&quot;,
        &quot;database.history.producer.sasl.mechanism&quot;: &quot;PLAIN&quot;,
       &quot;database.history.producer.sasl.jaas.config&quot;:         &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;password\&quot;;&quot;,
   &quot;database.history.producer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
    &quot;database.history.consumer.sasl.jaas.config&quot;:          &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot;   password=\&quot;password\&quot;;&quot;,
     &quot;database.history.consumer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
       &quot;database.history.consumer.sasl.mechanism&quot;: &quot;PLAIN&quot;
   }
}'
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[linux 安装服务器资源监控 prometheus远程写入]]></title>
        <id>https://oldcamel.run/post/linux-an-zhuang-fu-wu-qi-zi-yuan-jian-kong-prometheus-yuan-cheng-xie-ru/</id>
        <link href="https://oldcamel.run/post/linux-an-zhuang-fu-wu-qi-zi-yuan-jian-kong-prometheus-yuan-cheng-xie-ru/">
        </link>
        <updated>2021-03-11T01:07:36.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1安装prometheus">1.安装prometheus</h2>
<pre><code>wget -c https://github.com/prometheus/prometheus/releases/download/v2.23.0/prometheus-2.23.0.linux-amd64.tar.gz 
tar zxvf prometheus-2.23.0.linux-amd64.tar.gz  -C /opt/ 
cd /opt/ 
ln -s prometheus-2.23.0.linux-amd64 prometheus 
cat &gt; /etc/systemd/system/prometheus.service &lt;&lt;EOF 
[Unit] 
Description=prometheus 
After=network.target 
[Service] 
Type=simple 
WorkingDirectory=/opt/prometheus 
ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml
LimitNOFILE=65536 
PrivateTmp=true 
RestartSec=2 
StartLimitInterval=0 
Restart=always 
[Install] 
WantedBy=multi-user.target 
EOF 
systemctl daemon-reload  
systemctl enable prometheus 
systemctl start prometheus 

</code></pre>
<h3 id="2配置prometheus">2.配置Prometheus</h3>
<pre><code>cat &gt; /opt/prometheus/prometheus.yml &lt;&lt;EOF 
# my global config 
global: 
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. 
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. 
  # scrape_timeout is set to the global default (10s). 
  external_labels:
        tenant: &quot;140test&quot;
remote_write:
  - url: &quot;url&quot;
    basic_auth:
      username: 用户名
      password: 密码
# Alertmanager configuration 
alerting: 
  alertmanagers: 
  - static_configs: 
    - targets: 
      # - alertmanager:9093 
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'. 
rule_files: 
  # - &quot;first_rules.yml&quot; 
  # - &quot;second_rules.yml&quot; 
# A scrape configuration containing exactly one endpoint to scrape: 
# Here it's Prometheus itself. 
scrape_configs: 
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. 
  - job_name: 'servers' 
    file_sd_configs: 
    - refresh_interval: 61s 
      files: 
        - /opt/prometheus/servers/*.json 
EOF 

</code></pre>
<h2 id="3创建node配置文件">3.创建node配置文件</h2>
<pre><code>mkdir -p /opt/prometheus/servers
cd /opt/prometheus/servers
vim json.json
[     
    { 
        &quot;targets&quot;: [ 
            “xxx.xxx.xxx.xxx:9100&quot; 
        ], 
        &quot;labels&quot;: { 
            &quot;instance&quot;: &quot;xxx.xxx.xxx.xxx&quot;, 
            &quot;job&quot;: &quot;node_exporter&quot; 
        } 
    }
   
] 
</code></pre>
<h2 id="安装node_exporter">安装node_exporter</h2>
<pre><code>Wget https://github.com/prometheus/node_exporter/releases/download/v1.0.1/node_exporter-1.0.1.linux-amd64.tar.gz 
tar zxvf node_exporter-1.0.1.linux-amd64.tar.gz -C /opt/ 
cd /opt/ 
ln -s  node_exporter-1.0.1.linux-amd64 node_exporter 
cat &gt; /etc/systemd/system/node_exporter.service &lt;&lt;EOF 
[Unit] 
Description=node_exporter 
After=network.target 
[Service] 
Type=simple 
WorkingDirectory=/opt/node_exporter 
ExecStart=/opt/node_exporter/node_exporter 
LimitNOFILE=65536 
PrivateTmp=true 
RestartSec=2 
StartLimitInterval=0 
Restart=always 
[Install] 
WantedBy=multi-user.target 
EOF 
systemctl daemon-reload 
systemctl enable node_exporter 
systemctl start node_exporter 
systemctl restart prometheus 

</code></pre>
<h2 id="查看服务日志命令">查看服务日志命令</h2>
<pre><code>journalctl -u prometheus
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka实现sqlserver的CDC数据实时变更]]></title>
        <id>https://oldcamel.run/post/kafka-shi-xian-sqlserver-de-cdc-shu-ju-shi-shi-bian-geng/</id>
        <link href="https://oldcamel.run/post/kafka-shi-xian-sqlserver-de-cdc-shu-ju-shi-shi-bian-geng/">
        </link>
        <updated>2021-01-08T02:29:39.000Z</updated>
        <content type="html"><![CDATA[<h2 id="安装sqlserver">安装sqlserver</h2>
<pre><code>#!/bin/bash -e
# Password for the SA user (required)
# 设置密码
MSSQL_SA_PASSWORD='test@12345678'

# Product ID of the version of SQL server you're installing
# Must be evaluation, developer, express, web, standard, enterprise, or your 25 digit product key
# Defaults to developer
# 选择版本，有多种版本可供原则，具体版本标识符可自行百度
MSSQL_PID='evaluation'

# Install SQL Server Agent (recommended)
SQL_ENABLE_AGENT='y'

# Install SQL Server Full Text Search (optional)
# SQL_INSTALL_FULLTEXT='y'

# Create an additional user with sysadmin privileges (optional)
# 新建一个额外添加的用户，（可选）
# SQL_INSTALL_USER='&lt;Username&gt;'
# SQL_INSTALL_USER_PASSWORD='&lt;YourStrong!Passw0rd&gt;'

if [ -z $MSSQL_SA_PASSWORD ]
then
  echo Environment variable MSSQL_SA_PASSWORD must be set for unattended install
  exit 1
fi

# --------------------------- 远程拉包 并安装的过程
echo Adding Microsoft repositories...
sudo curl -o /etc/yum.repos.d/mssql-server.repo https://packages.microsoft.com/config/rhel/7/mssql-server-2017.repo
sudo curl -o /etc/yum.repos.d/msprod.repo https://packages.microsoft.com/config/rhel/7/prod.repo

echo Installing SQL Server...
sudo yum install -y mssql-server

# --------------------------- 下面给出 本地离线rpm包安装部分脚本
echo ：Local Installing SQL Server...
sudo yum localinstall -y ./sqlserver2017.rpm



# 执行sqlserver的配置
echo Running mssql-conf setup...
sudo MSSQL_SA_PASSWORD=$MSSQL_SA_PASSWORD \
     MSSQL_PID=$MSSQL_PID \
     /opt/mssql/bin/mssql-conf -n setup accept-eula

echo Installing mssql-tools and unixODBC developer...
sudo ACCEPT_EULA=Y yum install -y mssql-tools unixODBC-devel

# Add SQL Server tools to the path by default:
echo Adding SQL Server tools to your path...
echo PATH=&quot;$PATH:/opt/mssql-tools/bin&quot; &gt;&gt; ~/.bash_profile
echo 'export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;' &gt;&gt; ~/.bashrc
source ~/.bashrc

# Optional Enable SQL Server Agent :
if [ ! -z $SQL_ENABLE_AGENT ]
then
  echo Enable SQL Server Agent...
  sudo /opt/mssql/bin/mssql-conf set sqlagent.enabled true
  sudo systemctl restart mssql-server
fi

# Optional SQL Server Full Text Search installation:
if [ ! -z $SQL_INSTALL_FULLTEXT ]
then
    echo Installing SQL Server Full-Text Search...
    sudo yum install -y mssql-server-fts
fi

# Configure firewall to allow TCP port 1433:
# 配置防火墙放行1433端口，懒省事直接关掉防火墙亦可
echo Configuring firewall to allow traffic on port 1433...
sudo firewall-cmd --zone=public --add-port=1433/tcp --permanent
sudo firewall-cmd --reload

# Example of setting post-installation configuration options
# Set trace flags 1204 and 1222 for deadlock tracing:
#echo Setting trace flags...
#sudo /opt/mssql/bin/mssql-conf traceflag 1204 1222 on

# Restart SQL Server after making configuration changes:
# 重启
echo Restarting SQL Server...
sudo systemctl restart mssql-server

# Connect to server and get the version:
# 官方给出的测试链接脚本
counter=1
errstatus=1
while [ $counter -le 5 ] &amp;&amp; [ $errstatus = 1 ]
do
  echo Waiting for SQL Server to start...
  sleep 5s
  /opt/mssql-tools/bin/sqlcmd \
    -S localhost \
    -U SA \
    -P $MSSQL_SA_PASSWORD \
    -Q &quot;SELECT @@VERSION&quot; 2&gt;/dev/null
  errstatus=$?
  ((counter++))
done

# Display error if connection failed:
if [ $errstatus = 1 ]
then
  echo Cannot connect to SQL Server, installation aborted
  exit $errstatus
fi

# Optional new user creation:
if [ ! -z $SQL_INSTALL_USER ] &amp;&amp; [ ! -z $SQL_INSTALL_USER_PASSWORD ]
then
  echo Creating user $SQL_INSTALL_USER
  /opt/mssql-tools/bin/sqlcmd \
    -S localhost \
    -U SA \
    -P $MSSQL_SA_PASSWORD \
    -Q &quot;CREATE LOGIN [$SQL_INSTALL_USER] WITH PASSWORD=N'$SQL_INSTALL_USER_PASSWORD', DEFAULT_DATABASE=[master], CHECK_EXPIRATION=ON, CHECK_POLICY=ON; ALTER SERVER ROLE [sysadmin] ADD MEMBER [$SQL_INSTALL_USER]&quot;
fi

echo Done!
</code></pre>
<p>运行脚本等着安装完成</p>
<h2 id="开启表的cdc">开启表的cdc</h2>
<h3 id="创建shihu数据库">创建shihu数据库</h3>
<h3 id="建测试表">建测试表</h3>
<pre><code>IF EXISTS (SELECT * FROM sys.all_objects WHERE object_id = OBJECT_ID(N'[dbo].[dt_test]') AND type IN ('U'))
	DROP TABLE [dbo].[dt_test]
GO

CREATE TABLE [dbo].[dt_test] (
  [tid] int  NOT NULL,
  [tname] nvarchar(200) COLLATE SQL_Latin1_General_CP1_CI_AS  NULL,
  [tidcard] nvarchar(200) COLLATE SQL_Latin1_General_CP1_CI_AS  NULL,
  [tbirthday] date  NULL,
  [tmobile] nvarchar(200) COLLATE SQL_Latin1_General_CP1_CI_AS  NULL,
  [temail] nvarchar(200) COLLATE SQL_Latin1_General_CP1_CI_AS  NULL,
  [tgender] bigint  NULL,
  [tcreate_time] datetime  NULL
)
GO

ALTER TABLE [dbo].[dt_test] SET (LOCK_ESCALATION = TABLE)
GO


-- ----------------------------
-- Primary Key structure for table dt_test
-- ----------------------------
ALTER TABLE [dbo].[dt_test] ADD CONSTRAINT [PK__dt_test__DC105B0FA908205A] PRIMARY KEY CLUSTERED ([tid])
WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON)  
ON [PRIMARY]
GO

</code></pre>
<h3 id="开启cdc">开启cdc</h3>
<pre><code>USE shihu
GO
EXEC sys.sp_cdc_enable_db
GO

USE shihu
GO
EXEC sys.sp_cdc_enable_table
@source_schema = 'dbo',
@source_name   = ‘dt_test’,     
@role_name     = NULL,
@filegroup_name = 'PRIMARY',      
@supports_net_changes = 1
GO
</code></pre>
<h2 id="下载kafka插件">下载kafka插件</h2>
<h3 id="官方文档">官方文档</h3>
<p><a href="https://debezium.io/documentation/reference/1.3/connectors/sqlserver.html">https://debezium.io/documentation/reference/1.3/connectors/sqlserver.html</a></p>
<h3 id="下载">下载</h3>
<p><a href="https://repo1.maven.org/maven2/io/debezium/debezium-connector-sqlserver/1.2.5.Final/debezium-connector-sqlserver-1.2.5.Final-plugin.tar.gz">https://repo1.maven.org/maven2/io/debezium/debezium-connector-sqlserver/1.2.5.Final/debezium-connector-sqlserver-1.2.5.Final-plugin.tar.gz</a></p>
<h3 id="创建插件目录">创建插件目录</h3>
<p>在kafka跟目录创建 kafka_connect_plugins 目录<br>
将下载的包解压到此目录中<br>
<img src="https://oldcamel.run/post-images/1610074594464.png" alt="" loading="lazy"></p>
<h3 id="修改kafkaconfigconnect-distributeproperties">修改kafka/config/connect-distribute.properties</h3>
<p>bootstrap.servers=IP:9092<br>
plugin.path= /kafka路径/kafka_connect_plugins</p>
<h3 id="启动kafka-connect">启动kafka-connect</h3>
<pre><code>./bin/connect-distributed.sh  config/connect-distributed.properties &gt;logs/ksc.log &amp;
</code></pre>
<p>开启成功的标志,postman可以使用访问端口8083（默认的端口号,可以在connect-distributed.properties 更改）</p>
<h4 id="rest-api">rest api</h4>
<pre><code>GET /connectors – 返回所有正在运行的connector名
POST /connectors – 新建一个connector; 请求体必须是json格式并且需要包含name字段和config字段，name是connector的名字，config是json格式，必须包含你的connector的配置信息。
GET /connectors/{name} – 获取指定connetor的信息
GET /connectors/{name}/config – 获取指定connector的配置信息
PUT /connectors/{name}/config – 更新指定connector的配置信息
GET /connectors/{name}/status – 获取指定connector的状态，包括它是否在运行、停止、或者失败，如果发生错误，还会列出错误的具体信息。
GET /connectors/{name}/tasks – 获取指定connector正在运行的task。
GET /connectors/{name}/tasks/{taskid}/status – 获取指定connector的task的状态信息
PUT /connectors/{name}/pause – 暂停connector和它的task，停止数据处理知道它被恢复。
PUT /connectors/{name}/resume – 恢复一个被暂停的connector
POST /connectors/{name}/restart – 重启一个connector，尤其是在一个connector运行失败的情况下比较常用
POST /connectors/{name}/tasks/{taskId}/restart – 重启一个task，一般是因为它运行失败才这样做。
DELETE /connectors/{name} – 删除一个connector，停止它的所有task并删除配置。
</code></pre>
<h4 id="添加sqlserver-connect">添加sqlserver connect</h4>
<pre><code>curl --location --request POST 'http://localhost:8083/connectors' \
--header 'Content-Type: application/json' \
--data-raw '{
    &quot;name&quot;: &quot;sqlserver178-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.sqlserver.SqlServerConnector&quot;,
        &quot;database.hostname&quot;: &quot;sqlserver的ip&quot;,
        &quot;database.port&quot;: &quot;1433&quot;,
        &quot;database.user&quot;: &quot;sa&quot;,
        &quot;database.password&quot;: &quot;test@12345678&quot;,
        &quot;database.dbname&quot;: &quot;shihu&quot;,
        &quot;database.server.name&quot;: &quot;fullfillment&quot;,
        &quot;table.whitelist&quot;: &quot;dbo.dt_test&quot;,
        &quot;database.history.kafka.bootstrap.servers&quot;: &quot;kafka的IP:9092&quot;,
        &quot;database.history.kafka.topic&quot;: &quot;dbhistory.fullfillment&quot;,
        &quot;database.history.producer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
        &quot;database.history.producer.sasl.mechanism&quot;: &quot;PLAIN&quot;,
        &quot;database.history.producer.sasl.jaas.config&quot;: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;123\&quot;;&quot;,
        &quot;database.history.consumer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
        &quot;database.history.consumer.sasl.mechanism&quot;: &quot;PLAIN&quot;,
        &quot;database.history.consumer.sasl.jaas.config&quot;: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;123\&quot;;&quot;
    }
}'
</code></pre>
<h3 id="消费信息">消费信息</h3>
<h4 id="consumerpreperties配置">consumer.preperties配置</h4>
<pre><code>bootstrap.servers=localhost:9092
group.id=test-consumer-group
security.protocol=SASL_PLAINTEXT
sasl.mechanism=PLAIN
</code></pre>
<h4 id="修改器kafka-console-consumersh为kafka-console-consumer-saalsh倒数第二行添加">修改器kafka-console-consumer.sh为kafka-console-consumer-saal.sh倒数第二行添加</h4>
<pre><code>export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/opt/kafka/kafka_2.13-2.6.0/config/kafka_client_jaas.conf&quot;
</code></pre>
<h4 id="启动">启动</h4>
<pre><code>./bin/kafka-console-consumer-saal.sh --bootstrap-server localhost:9092 --topic fullfillment.dbo.dt_test --consumer.config config/consumer.properties
</code></pre>
<h4 id="消息示例">消息示例</h4>
<pre><code>{
    &quot;schema&quot;:{
        &quot;type&quot;:&quot;struct&quot;,
        &quot;fields&quot;:Array[6],
        &quot;optional&quot;:false,
        &quot;name&quot;:&quot;fullfillment.dbo.dt_test.Envelope&quot;
    },
    &quot;payload&quot;:{
        &quot;before&quot;:{
            &quot;tid&quot;:1,
            &quot;tname&quot;:&quot;222&quot;,
            &quot;tidcard&quot;:&quot;2&quot;,
            &quot;tbirthday&quot;:-25567,
            &quot;tmobile&quot;:&quot;1&quot;,
            &quot;temail&quot;:&quot;1&quot;,
            &quot;tgender&quot;:2,
            &quot;tcreate_time&quot;:-2208988800000
        },
        &quot;after&quot;:{
            &quot;tid&quot;:1,
            &quot;tname&quot;:&quot;test&quot;,
            &quot;tidcard&quot;:&quot;2&quot;,
            &quot;tbirthday&quot;:-25567,
            &quot;tmobile&quot;:&quot;1&quot;,
            &quot;temail&quot;:&quot;1&quot;,
            &quot;tgender&quot;:2,
            &quot;tcreate_time&quot;:-2208988800000
        },
        &quot;source&quot;:Object{...},
        &quot;op&quot;:&quot;u&quot;,
        &quot;ts_ms&quot;:1610019731750,
        &quot;transaction&quot;:null
    }
}
</code></pre>
<h4 id="oracle示例">oracle示例</h4>
<pre><code>
curl --location --request POST 'http://localhost:8083/connectors/' \
--header 'Content-Type: application/json' \
--data-raw '
{
    &quot;name&quot;: &quot;oracle-61-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;com.ecer.kafka.connect.oracle.OracleSourceConnector&quot;,
        &quot;db.name.alias&quot;: &quot;61test&quot;,
        &quot;tasks.max&quot;: 1,
        &quot;topic&quot;: &quot;kol&quot;,
        &quot;db.name&quot;: &quot;portaldb&quot;,
        &quot;db.hostname&quot;: &quot;oralce连接host地址&quot;,
        &quot;db.port&quot;: 1521,
        &quot;db.user&quot;: &quot;info&quot;,
        &quot;db.user.password&quot;: &quot;111111&quot;,
        &quot;db.fetch.size&quot;: 1,
        &quot;table.whitelist&quot;: &quot;INFO.*,SPAUTH.*,WORKFLOW.*,FLOWABLE.*,OA.*&quot;,
        &quot;table.blacklist&quot;: &quot;&quot;,
        &quot;parse.dml.data&quot;: true,
        &quot;reset.offset&quot;: false,
        &quot;multitenant&quot;: false
    }
}
</code></pre>
<h3 id="mysql示例">mysql示例</h3>
<pre><code>curl --location --request POST 'http://localhost:8083/connectors/' \
--header 'Content-Type: application/json' \
--data-raw '
{
  &quot;name&quot;: &quot;140mysql-connector&quot;, 
  &quot;config&quot;: {
    &quot;connector.class&quot;: &quot;io.debezium.connector.mysql.MySqlConnector&quot;, 
    &quot;database.hostname&quot;: &quot;localhost&quot;, 
    &quot;database.port&quot;: &quot;3306&quot;, 
    &quot;database.user&quot;: &quot;root&quot;, 
    &quot;database.password&quot;: &quot;111111&quot;, 
    &quot;database.server.id&quot;: &quot;184054&quot;, 
    &quot;database.server.name&quot;: &quot;fullfillment140ms&quot;, 
    &quot;database.whitelist&quot;:&quot;test&quot;,
    &quot;database.history.kafka.bootstrap.servers&quot;: &quot;localhost:9092&quot;, 
    &quot;database.history.kafka.topic&quot;: &quot;dbhistory.fullfillment140ms&quot;, 
    &quot;include.schema.changes&quot;: &quot;false&quot;,
        &quot;database.history.producer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
        &quot;database.history.producer.sasl.mechanism&quot;: &quot;PLAIN&quot;,
        &quot;database.history.producer.sasl.jaas.config&quot;: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;123\&quot;;&quot;,
        &quot;database.history.consumer.security.protocol&quot;: &quot;SASL_PLAINTEXT&quot;,
        &quot;database.history.consumer.sasl.mechanism&quot;: &quot;PLAIN&quot;,
        &quot;database.history.consumer.sasl.jaas.config&quot;: &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;admin\&quot; password=\&quot;123\&quot;;&quot;
    }
}
</code></pre>
<h3 id="查看topic-list">查看topic list</h3>
<pre><code>bin/kafka-topics.sh --zookeeper localhost --list
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kafka开启SASL用户名密码认证]]></title>
        <id>https://oldcamel.run/post/kafka-kai-qi-sasl-yong-hu-ming-mi-ma-ren-zheng/</id>
        <link href="https://oldcamel.run/post/kafka-kai-qi-sasl-yong-hu-ming-mi-ma-ren-zheng/">
        </link>
        <updated>2021-01-08T01:51:25.000Z</updated>
        <content type="html"><![CDATA[<h2 id="创建kafka_server_jaasconf文件">创建kafka_server_jaas.conf文件</h2>
<p>config目录下创建kafka_server_jaas.conf文件</p>
<pre><code>KafkaServer {
  org.apache.kafka.common.security.plain.PlainLoginModule required
  username=&quot;admin&quot;
  password=&quot;123&quot;
  user_admin=&quot;123&quot;
  user_yunzai=&quot;123&quot;;
};
</code></pre>
<h2 id="创建kafka_client_jaasconf文件">创建kafka_client_jaas.conf文件</h2>
<p>config目录下创建kafka_client_jaas.conf文件</p>
<pre><code>KafkaClient {
        org.apache.kafka.common.security.plain.PlainLoginModule required
        username=&quot;admin&quot;
        password=&quot;123&quot;;
};
</code></pre>
<h2 id="修改serverproperties">修改server.properties</h2>
<pre><code>listeners=SASL_PLAINTEXT://IP:9092
advertised.listeners=SASL_PLAINTEXT://IP:9092
security.inter.broker.protocol=SASL_PLAINTEXT
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.inter.broker.protocol=PLAIN
authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
super.users=User:admin;
</code></pre>
<h2 id="修改kafaka启动脚本">修改kafaka启动脚本</h2>
<p>修改bin目录下kafka_start.sh<br>
在倒数第二行添加kafka_server_jaas.conf的全路径</p>
<pre><code>export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/opt/kafka/kafka_2.13-2.6.0/config/kafka_server_jaas.conf&quot;
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://oldcamel.run/post-images/1610071605941.png" alt="" loading="lazy"></figure>
<h2 id="可选为特定用户添加特定topic的acl授权">（可选）为特定用户添加特定topic的acl授权</h2>
<p>如下表示为用户yunzai添加topic nginx-log的读写权限。</p>
<pre><code>./bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 -add --allow-principal User:yunzai  --operation Read --operation Write --topic testyunzai
</code></pre>
<p>验证授权</p>
<pre><code>./bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --list --topic testyunzai
</code></pre>
<h3 id="生产者消费者验证">生产者消费者验证</h3>
<h4 id="生产者">生产者</h4>
<p>1.以用户yunzai为例，创建JAAS认证文件yunzai_jaas.conf放在config目录下，内容如下:</p>
<pre><code>KafkaClient {
org.apache.kafka.common.security.plain.PlainLoginModule required
username=&quot;yunzai&quot;
password=&quot;123&quot;;
};
</code></pre>
<p>2.拷贝bin/kafka-console-producer.sh为bin/yunzai-kafka-console-producer.sh，并将JAAS文件作为一个JVM参数传给console producer</p>
<p>倒数第二行添加</p>
<pre><code>export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/opt/kafka/kafka_2.13-2.6.0/config/yunzai_jaas.conf&quot;
</code></pre>
<p>3.创建文件producer.config指定如下属性：</p>
<pre><code>security.protocol=SASL_PLAINTEXT
sasl.mechanism=PLAIN
</code></pre>
<p>4.启动producer</p>
<pre><code>./bin/yunzai-kafka-console-producer.sh --broker-list IP:9092 --topic testyunzai --producer.config producer.config
</code></pre>
<h4 id="消费者">消费者</h4>
<p>1.以用户yunzai为例，创建JAAS认证文件yunzai_jaas.conf放在config目录下，如果用户跟生产者是同一个，可以复用上面生产者的JAAS文件，内容如下:</p>
<pre><code>KafkaClient {
org.apache.kafka.common.security.plain.PlainLoginModule required
username=&quot;yunzai&quot;
password=&quot;123&quot;;
};
</code></pre>
<p>2.拷贝bin/kafka-console-consumer.sh为bin/yunzai-kafka-console-consumer.sh，并将JAAS文件作为一个JVM参数传给console consumer<br>
倒数第二行添加</p>
<pre><code>export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/opt/kafka/kafka_2.13-2.6.0/config/yunzai_jaas.conf&quot;
</code></pre>
<p>3.创建文件consumer.config指定如下属性：</p>
<pre><code>security.protocol=SASL_PLAINTEXT
sasl.mechanism=PLAIN
group.id=test
</code></pre>
<p>4.启动consumer</p>
<pre><code>./bin/yunzai-kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic testyunzai --from-beginning --consumer.config consumer.config
</code></pre>
<h3 id="java-beam客户端认证">java beam客户端认证</h3>
<p>beam设置</p>
<pre><code class="language-java">   final Map&lt;String, Object&gt; immutableMap = new ImmutableMap.Builder&lt;String, Object&gt;()
                .put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)
                .put(ConsumerConfig.GROUP_ID_CONFIG, options.getGroupid())
                .put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true)
                .put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, &quot;SASL_PLAINTEXT&quot;)
                .put(SaslConfigs.SASL_MECHANISM, &quot;PLAIN&quot;)
                .put(SaslConfigs.SASL_JAAS_CONFIG, &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;&quot; + options.getKafkaUsername() + &quot;\&quot; password=\&quot;&quot; + options.getKafkaPassword() + &quot;\&quot;;&quot;)
                .build();
</code></pre>
]]></content>
    </entry>
</feed>