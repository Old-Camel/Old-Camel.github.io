<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title> Beam+Kafka同步Oracle日志到ClickHouse | Old Camel</title>
<meta name="description" content="日常开发记录 
&lt;div&gt;&lt;iframe frameborder=&#34;no&#34; border=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; width=330 height=86 src=&#34;//music.163.com/outchain/player?type=2&amp;id=18611643&amp;auto=1&amp;height=66&#34;&gt;&lt;/iframe&gt;&lt;/div&gt;">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="shortcut icon" href="https://oldcamel.run/favicon.ico?v=1624876951447">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://unpkg.com/papercss@1.6.1/dist/paper.min.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://oldcamel.run/styles/main.css">


<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>


<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />

<script async src="https://www.googletagmanager.com/gtag/js?id=G-3TQNJ5FTMN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3TQNJ5FTMN');
</script>


  </head>
  <body>
  
    <nav class="navbar border fixed split-nav">
  <div class="nav-brand">
    <h3><a href="https://oldcamel.run">Old Camel</a></h3>
  </div>
  <div class="collapsible">
    <input id="collapsible1" type="checkbox" name="collapsible1">
    <button>
      <label for="collapsible1">
        <div class="bar1"></div>
        <div class="bar2"></div>
        <div class="bar3"></div>
      </label>
    </button>
    <div class="collapsible-body">
      <ul class="inline">
        
          <li>
            
              <a href="/" class="menu">
                首页
              </a>
            
          </li>
        
          <li>
            
              <a href="/archives" class="menu">
                归档
              </a>
            
          </li>
        
          <li>
            
              <a href="/tags" class="menu">
                标签
              </a>
            
          </li>
        
          <li>
            
              <a href="/post/about" class="menu">
                关于
              </a>
            
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div id="top" class="row site">
      <div class="sm-12 md-8 col">
        <div class="paper">
          <article class="article">
            <h1> Beam+Kafka同步Oracle日志到ClickHouse</h1>
            <p class="article-meta">
              2020-12-10
              
                <a href="https://oldcamel.run/tag/KOvNrkSXn/" class="badge secondary">
                  beam
                </a>
              
                <a href="https://oldcamel.run/tag/AfOZDj8Cpm/" class="badge success">
                  kafka
                </a>
              
                <a href="https://oldcamel.run/tag/L9nUjvZyjL/" class="badge warning">
                  oracle
                </a>
              
                <a href="https://oldcamel.run/tag/xOjaMtgYtD/" class="badge warning">
                  clickhouse
                </a>
              
            </p>
            
              <img src="https://oldcamel.run/post-images/apache-beam-tong-bu-oracle-ri-zhi-dao-clickhouse.JPG" alt=" Beam+Kafka同步Oracle日志到ClickHouse">
            
            <div class="post-content">
              <p>用kafka的oracle connect插件存储oracle日志，用beam读取kafka数据插入到clickhouse中</p>
<h2 id="oracle配置">oracle配置</h2>
<h3 id="archivelog模式">archivelog模式</h3>
<p>数据库必须处于archivelog模式，并且必须启用补充日志记录<br>
在数据库服务器上执行</p>
<pre><code>sqlplus / as sysdba    
SQL&gt;shutdown immediate
SQL&gt;startup mount
SQL&gt;alter database archivelog;
SQL&gt;alter database open;
</code></pre>
<h3 id="启用补充日志记录">启用补充日志记录</h3>
<pre><code>sqlplus / as sysdba    
SQL&gt;alter database add supplemental log data (all) columns;
</code></pre>
<h2 id="kafka配置">kafka配置</h2>
<h3 id="插件配置文件">插件配置文件</h3>
<p>在$KAFKA_HOME/config 目录新建OracleSourceConnector.properties配置文件，<br>
文件内示例配置</p>
<pre><code>name=oracle-logminer-connector
connector.class=com.ecer.kafka.connect.oracle.OracleSourceConnector
db.name.alias=test
tasks.max=1
topic=cdctest
db.name=testdb
db.hostname=10.1.X.X
db.port=1521
db.user=kminer
db.user.password=kminerpass
db.fetch.size=1
table.whitelist=TEST.*,TEST2.TABLE2
table.blacklist=TEST2.TABLE3
parse.dml.data=true
reset.offset=false
multitenant=false
</code></pre>
<h3 id="配置说明">配置说明</h3>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>String</td>
<td>连接器名称</td>
</tr>
<tr>
<td>connector.class</td>
<td>String</td>
<td>此连接器的Java类的名称</td>
</tr>
<tr>
<td>db.name.alias</td>
<td>String</td>
<td>数据库的标识符名称（例如Test，Dev，Prod）或用于标识数据库的特定名称该名称将用作主题和架构名称的标头</td>
</tr>
<tr>
<td>tasks.max</td>
<td>Integer</td>
<td>创建的最大任务数此连接器使用单个任务.</td>
</tr>
<tr>
<td>topic</td>
<td>String</td>
<td>消息将写入的主题的名称如果设置了值，则所有消息都将写入此声明的topic，如果未设置，则将为每个数据库表动态创建一个主题</td>
</tr>
<tr>
<td>db.name</td>
<td>String</td>
<td>要连接的数据库的服务名称或sid通常使用数据库服务名称</td>
</tr>
<tr>
<td>db.hostname</td>
<td>String</td>
<td>Oracle数据库服务器的IP地址或主机名</td>
</tr>
<tr>
<td>db.port</td>
<td>Integer</td>
<td>Oracle数据库服务器的端口号</td>
</tr>
<tr>
<td>db.user</td>
<td>String</td>
<td>数据库的用户名</td>
</tr>
<tr>
<td>db.user.password</td>
<td>String</td>
<td>数据库用户密码</td>
</tr>
<tr>
<td>db.fetch.size</td>
<td>Integer</td>
<td>此配置属性设置Oracle行提取大小值</td>
</tr>
<tr>
<td>table.whitelist</td>
<td>String</td>
<td>白名单格式为用户名.表名用逗号分隔，如果要收集用户下的所有的表，用用户名.*</td>
</tr>
<tr>
<td>parse.dml.data</td>
<td>Boolean</td>
<td>如果为true，则将捕获的sql DML语句解析为字段和值;如果为false，则仅发布sql DML语句</td>
</tr>
<tr>
<td>reset.offset</td>
<td>Boolean</td>
<td>如果为true，则在连接器启动时将偏移值设置为数据库的当前SCN如果为false，则连接器将从上一个偏移值开始</td>
</tr>
<tr>
<td>start.scn</td>
<td>Long</td>
<td>如果设置此属性，则将偏移值设置为该指定值，并且logminer将从此SCN启动如果连接器希望从所需的SCN启动，则可以使用此属性</td>
</tr>
<tr>
<td>multitenant</td>
<td>Boolean</td>
<td>如果为true，则启用多租户支持如果为false，将使用单实例配置</td>
</tr>
<tr>
<td>table.blacklist</td>
<td>String</td>
<td>黑名单格式为用户名.表名用逗号分隔，如果要收集用户下的所有的表，用用户名.*.</td>
</tr>
<tr>
<td>dml.types</td>
<td>String</td>
<td>以逗号分隔的DML操作列表（INSERT，UPDATE，DELETE）如果未指定，则将执行复制所有DML操作的默认行为，如果指定，则仅捕获指定的操作</td>
</tr>
</tbody>
</table>
<p>以上为机翻，原说明文档地址见<br>
<a href="https://github.com/erdemcer/kafka-connect-oracle/blob/master/README.md">https://github.com/erdemcer/kafka-connect-oracle/blob/master/README.md</a></p>
<h3 id="添加kafka插件包">添加kafka插件包</h3>
<p><a href="https://www.jianguoyun.com/p/DSQTC_AQz5aGCRiHodMD"><mark>kafka-connect-oracle-1.0.68.jar</mark></a>和相应版本的oracle的驱动包放入到 $KAFKA_HOME/lib文件夹中</p>
<h3 id="启动插件">启动插件</h3>
<pre><code>cd $KAFKA_HOME
./bin/connect-standalone.sh ./config/connect-standalone.properties ./config/OracleSourceConnector.properties
</code></pre>
<h3 id="kafka消息说明">kafka消息说明</h3>
<table>
<thead>
<tr>
<th>字段</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>SCN</td>
<td>数据库日志时间</td>
</tr>
<tr>
<td>SEG_OWNER</td>
<td>数据库用户名</td>
</tr>
<tr>
<td>TABLE_NAME</td>
<td>数据库表名</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td>时间戳</td>
</tr>
<tr>
<td>SQL_REDO</td>
<td>执行的sql语句</td>
</tr>
<tr>
<td>OPERATION</td>
<td>操作</td>
</tr>
<tr>
<td>DATA</td>
<td>更新后的数据</td>
</tr>
<tr>
<td>BEFORE</td>
<td>更新前的数据</td>
</tr>
</tbody>
</table>
<h2 id="clickhouse-建表">ClickHouse 建表</h2>
<pre><code class="language-sql">CREATE TABLE default.ODB_LOG
(
SCN        Int64,
SEG_OWNER  String,
TABLE_NAME String,
`TIMESTAMP` DateTime,
SQL_REDO String,
OPERATION String,
 `DATA` String,
`BEFORE` String
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(TIMESTAMP)
ORDER BY  (SEG_OWNER,TABLE_NAME,OPERATION,TIMESTAMP )
SETTINGS index_granularity=8192;
</code></pre>
<h2 id="beam-程序">Beam 程序</h2>
<h3 id="maven添加-依赖包">maven添加 依赖包</h3>
<pre><code class="language-xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
            &lt;artifactId&gt;beam-sdks-java-io-clickhouse&lt;/artifactId&gt;
            &lt;version&gt;${beam.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
            &lt;artifactId&gt;beam-sdks-java-io-kafka&lt;/artifactId&gt;
            &lt;version&gt;${beam.version}&lt;/version&gt;
        &lt;/dependency&gt;
         &lt;dependency&gt;
            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
            &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
            &lt;version&gt;2.4.1&lt;/version&gt;
            &lt;!--        &lt;scope&gt;runtime&lt;/scope&gt;--&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
            &lt;artifactId&gt;beam-runners-flink-1.11&lt;/artifactId&gt;
            &lt;version&gt;${beam.version}&lt;/version&gt;
        &lt;/dependency&gt;

</code></pre>
<h3 id="创建配置参数类">创建配置参数类</h3>
<pre><code class="language-java">package com.yunzainfo.kol.config;

import org.apache.beam.runners.flink.FlinkPipelineOptions;
import org.apache.beam.sdk.options.Default;
import org.apache.beam.sdk.options.Description;
import org.apache.beam.sdk.options.PipelineOptions;
import org.apache.beam.sdk.options.Validation.Required;

/**
 * Created by IntelliJ IDEA
 * TODO: TODO
 *
 * @author: 徐成
 * Date: 2020/12/2
 * Time: 10:08 上午
 * Email: old_camel@163.com
 */
public interface KolOptions extends FlinkPipelineOptions {
//public interface OdcOptions extends PipelineOptions {
    @Description(&quot;kafka链接地址&quot;)
    @Required
    @Default.String(&quot;xxx.xxx.xxx.xxx:9092&quot;)
    String getBootstrapServers();
    void setBootstrapServers(String value);
    @Description(&quot;kafka 消息主题&quot;)
    @Required
    @Default.String(&quot;kol&quot;)
    String getTopic();
    void setTopic(String value);
    @Description(&quot;分组id&quot;)
    @Required
    @Default.String(&quot;bdf_kol&quot;)
    String getGroupid();
    void setGroupid(String value);
    @Description(&quot;kafka用户&quot;)
    @Required
    @Default.String(&quot;xxx&quot;)
    String getKafkaUsername();
    void setKafkaUsername(String kafkaUsername);
    @Description(&quot;kafka密码&quot;)
    @Required
    @Default.String(&quot;xxx&quot;)
    String getKafkaPassword();
    void setKafkaPassword(String kafkaPassword);
    @Description(&quot;ClickHouse连接地址&quot;)
    @Required
    @Default.String(&quot;xxx.xxx.xxx.xxx:xxxx/default&quot;)
    String getClickHouseUrl();
    void setClickHouseUrl(String value);
    @Description(&quot;ClickHouse用户名&quot;)
    @Required
    @Default.String(&quot;root&quot;)
    String getClickHouseUserName();
    void setClickHouseUserName(String value);
    @Description(&quot;ClickHouse密码&quot;)
    @Required
    @Default.String(&quot;xxx&quot;)
    String getClickHousePassword();
    void setClickHousePassword(String value);
    @Description(&quot;ClickHouse表&quot;)
    @Required
    @Default.String(&quot;ODB_LOG&quot;)
    String getClickHouseTableName();
    void setClickHouseTableName(String value);
}


</code></pre>
<h3 id="kafka消息映射类">kafka消息映射类</h3>
<pre><code class="language-java">package com.yunzainfo.kol.model;

import org.codehaus.jackson.annotate.JsonProperty;

import java.io.Serializable;
import java.util.Date;

/**
 * Created by IntelliJ IDEA
 * TODO: TODO
 *
 * @author: 徐成
 * Date: 2020/11/30
 * Time: 2:32 下午
 * Email: old_camel@163.com
 */
public class Payload implements Serializable {
    private static final long serialVersionUID = 1L;
    @JsonProperty(value = &quot;SCN&quot;)
    private Long SCN;
    @JsonProperty(value = &quot;SEG_OWNER&quot;)
    private String SEG_OWNER;
    @JsonProperty(value = &quot;TABLE_NAME&quot;)
    private String TABLE_NAME;
    @JsonProperty(value = &quot;TIMESTAMP&quot;)
    private Long TIMESTAMP;
    @JsonProperty(value = &quot;SQL_REDO&quot;)
    private String SQL_REDO;
    @JsonProperty(value = &quot;OPERATION&quot;)
    private String OPERATION;
    @JsonProperty(value = &quot;data&quot;)
    private Object DATA;
    @JsonProperty(value = &quot;before&quot;)
    private Object BEFORE;

    public static long getSerialVersionUID() {
        return serialVersionUID;
    }

    public Long getSCN() {
        return SCN;
    }

    public void setSCN(Long SCN) {
        this.SCN = SCN;
    }

    public String getSEG_OWNER() {
        return SEG_OWNER;
    }

    public void setSEG_OWNER(String SEG_OWNER) {
        this.SEG_OWNER = SEG_OWNER;
    }

    public String getTABLE_NAME() {
        return TABLE_NAME;
    }

    public void setTABLE_NAME(String TABLE_NAME) {
        this.TABLE_NAME = TABLE_NAME;
    }

    public Long getTIMESTAMP() {
        return TIMESTAMP;
    }

    public void setTIMESTAMP(Long TIMESTAMP) {
        this.TIMESTAMP = TIMESTAMP;
    }

    public String getSQL_REDO() {
        return SQL_REDO;
    }

    public void setSQL_REDO(String SQL_REDO) {
        this.SQL_REDO = SQL_REDO;
    }

    public String getOPERATION() {
        return OPERATION;
    }

    public void setOPERATION(String OPERATION) {
        this.OPERATION = OPERATION;
    }

    public Object getDATA() {
        return DATA;
    }

    public void setDATA(Object DATA) {
        this.DATA = DATA;
    }

    public Object getBEFORE() {
        return BEFORE;
    }

    public void setBEFORE(Object BEFORE) {
        this.BEFORE = BEFORE;
    }

    @Override
    public String toString() {
        return &quot;Payload{&quot; +
                &quot;SCN=&quot; + SCN +
                &quot;, SEG_OWNER='&quot; + SEG_OWNER + '\'' +
                &quot;, TABLE_NAME='&quot; + TABLE_NAME + '\'' +
                &quot;, TIMESTAMP=&quot; + TIMESTAMP +
                &quot;, SQL_REDO='&quot; + SQL_REDO + '\'' +
                &quot;, OPERATION='&quot; + OPERATION + '\'' +
                &quot;, DATA='&quot; + DATA + '\'' +
                &quot;, BEFORE='&quot; + BEFORE + '\'' +
                '}';
    }
}


</code></pre>
<h3 id="主程序">主程序</h3>
<pre><code class="language-java">package com.yunzainfo.kol;

import com.yunzainfo.kol.config.KolOptions;
import com.yunzainfo.kol.model.Payload;
import org.apache.beam.runners.flink.FlinkRunner;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.coders.SerializableCoder;
import org.apache.beam.sdk.io.clickhouse.ClickHouseIO;
import org.apache.beam.sdk.io.kafka.KafkaIO;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.schemas.Schema;
import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.transforms.Values;
import org.apache.beam.sdk.values.Row;
import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.codehaus.jackson.map.ObjectMapper;
import org.joda.time.DateTime;
import org.joda.time.Duration;

import java.io.IOException;
import java.util.LinkedHashMap;
import java.util.Map;

/**
 * Created by IntelliJ IDEA
 * TODO: TODO
 *
 * @author: 徐成
 * Date: 2020/11/27
 * Time: 5:49 下午
 * Email: old_camel@163.com
 */
public class KolApp {


    public static void main(String[] args) {
        KolOptions options = PipelineOptionsFactory.fromArgs(args).as(KolOptions.class);
        options.setRunner(FlinkRunner.class);
        runOdc(options);
    }

    public static Object isnull(Object o) {
        if (o == null) {
            return &quot;&quot;;
        } else {
            return o;
        }
    }

    public static void runOdc(KolOptions options) {
        Pipeline p = Pipeline.create(options);
        final Map&lt;String, Object&gt; immutableMap = new ImmutableMap.Builder&lt;String, Object&gt;()
                .put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)
                .put(ConsumerConfig.GROUP_ID_CONFIG, options.getGroupid())
                .put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true)
                .put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, &quot;SASL_PLAINTEXT&quot;)
                .put(SaslConfigs.SASL_MECHANISM, &quot;PLAIN&quot;)
                .put(SaslConfigs.SASL_JAAS_CONFIG, &quot;org.apache.kafka.common.security.plain.PlainLoginModule required username=\&quot;&quot; + options.getKafkaUsername() + &quot;\&quot; password=\&quot;&quot; + options.getKafkaPassword() + &quot;\&quot;;&quot;)
                .build();
        final Schema ckType = Schema.of(
                Schema.Field.of(&quot;SCN&quot;, Schema.FieldType.INT64.withNullable(true)),
                Schema.Field.of(&quot;SEG_OWNER&quot;, Schema.FieldType.STRING.withNullable(true)),
                Schema.Field.of(&quot;TABLE_NAME&quot;, Schema.FieldType.STRING.withNullable(true)),
                Schema.Field.of(&quot;TIMESTAMP&quot;, Schema.FieldType.DATETIME.withNullable(true)),
                Schema.Field.of(&quot;SQL_REDO&quot;, Schema.FieldType.STRING.withNullable(true)),
                Schema.Field.of(&quot;OPERATION&quot;, Schema.FieldType.STRING.withNullable(true)),
                Schema.Field.of(&quot;DATA&quot;, Schema.FieldType.STRING.withNullable(true)),
                Schema.Field.of(&quot;BEFORE&quot;, Schema.FieldType.STRING.withNullable(true))
        );
        p.apply(&quot;读取消息&quot;, KafkaIO.&lt;String, String&gt;read()
                .withBootstrapServers(options.getBootstrapServers())
                .withTopic(options.getTopic())
                .withKeyDeserializer(StringDeserializer.class)
                .withValueDeserializer(StringDeserializer.class)
                .withOffsetConsumerConfigOverrides(ImmutableMap.&lt;String, Object&gt;of(ConsumerConfig.GROUP_ID_CONFIG, options.getGroupid()))
                .withConsumerConfigUpdates(immutableMap)
                .withReadCommitted()
                .withoutMetadata())
                .apply(Values.create())
                .apply(&quot;转义Payload&quot;, ParDo.of(new DoFn&lt;String, Payload&gt;() {
                    private static final long serialVersionUID = 1L;

                    @ProcessElement
                    public void processElement(ProcessContext ctx) {
                        String element = ctx.element();
                        ObjectMapper mapper = new ObjectMapper();
                        try {
                            LinkedHashMap map = mapper.readValue(element, LinkedHashMap.class);                //Object payload = data.get(&quot;payload&quot;);
                            LinkedHashMap payloadMap = (LinkedHashMap) map.get(&quot;payload&quot;);
                            Payload payload = mapper.convertValue(payloadMap, Payload.class);
                            payload.setDATA(mapper.writeValueAsString(payload.getDATA()));
                            payload.setBEFORE(mapper.writeValueAsString(payload.getBEFORE()));
                            ctx.output(payload);
                        } catch (IOException e) {
                            e.printStackTrace();
                        }
                    }
                }))
                .setCoder(SerializableCoder.of(Payload.class))
                .apply(&quot;转换Row&quot;, ParDo.of(new DoFn&lt;Payload, Row&gt;() {
                    @ProcessElement
                    public void processElement(ProcessContext cxt) {
                        Payload payload = cxt.element();
                        Row alarmRow = Row.withSchema(ckType).addValues(
                                isnull(payload.getSCN()),
                                isnull(payload.getSEG_OWNER()),
                                isnull(payload.getTABLE_NAME()),
                                isnull(new DateTime(payload.getTIMESTAMP())),
                                isnull(payload.getSQL_REDO()),
                                isnull(payload.getOPERATION()),
                                isnull(payload.getDATA()),
                                isnull(payload.getBEFORE())
                        ).build();
                        cxt.output(alarmRow);
                    }
                })).setRowSchema(ckType)
                .apply(&quot;写入ClickHouse数据库&quot;,
                        ClickHouseIO.&lt;Row&gt;write(&quot;jdbc:clickhouse://&quot; + options.getClickHouseUrl() + &quot;?username=&quot; + options.getClickHouseUserName() + &quot;&amp;password=&quot; + options.getClickHousePassword(), options.getClickHouseTableName())
                                .withMaxRetries(3)//重试次数
                                .withInsertDeduplicate(true)//重复数据是否删除
                                .withMaxInsertBlockSize(1)//添加最大块的大小
                                .withInitialBackoff(Duration.standardSeconds(5))//初始退回时间
                                .withInsertDistributedSync(false)
                );
        p.run().waitUntilFinish();

    }
}

</code></pre>
<h2 id="把beam包放在flink上运行">把beam包放在flink上运行</h2>
<figure data-type="image" tabindex="1"><img src="https://oldcamel.run/post-images/1607602332596.png" alt="" loading="lazy"></figure>
<h2 id="clickhouse中的数据">clickhouse中的数据</h2>
<figure data-type="image" tabindex="2"><img src="https://oldcamel.run/post-images/1607602692592.png" alt="" loading="lazy"></figure>

            </div>
          </article>
        </div>
        <div class="paper" data-aos="fade-in">
          
        </div>
        
      </div>

      <div class="sm-12 md-4 col sidebar">
  <div class="paper info-container">
    <img src="https://oldcamel.run/images/avatar.png?v=1624876951447" class="no-responsive avatar">
    <div class="text-muted">日常开发记录 
<div><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=18611643&auto=1&height=66"></iframe></div></div>
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
  </div>
  <div class="paper">
    <div class="sidebar-title">
      最新文章
    </div>
    <div class="row">
      <ul>
        
          
            <li>
              <a href="https://oldcamel.run/post/duo-zu-hu-xi-tong-redis-huan-cun/">多租户系统redis 缓存</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/postgresql-shu-ju-lei-xing/">PostgreSql 数据类型</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/40-xin-de-kai-duan/">4.0 新的开端</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/kubernetes-wen-ti-chu-li-ji-lu/">Kubernetes 问题处理记录</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/flink-sql-shi-xian-cdc-shu-ju-shi-shi-tong-bu-te-shu-chu-li/">Flink Sql 实现CDC数据实时同步特殊处理</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/kafka-shi-xian-oracle-de-cdc-shu-ju-shi-shi-bian-geng/">Kafka实现oracle的CDC数据实时变更</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/linux-an-zhuang-fu-wu-qi-zi-yuan-jian-kong-prometheus-yuan-cheng-xie-ru/">linux 安装服务器资源监控 prometheus远程写入</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/kafka-shi-xian-sqlserver-de-cdc-shu-ju-shi-shi-bian-geng/">Kafka实现sqlserver的CDC数据实时变更</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/kafka-kai-qi-sasl-yong-hu-ming-mi-ma-ren-zheng/">Kafka开启SASL用户名密码认证</a>
            </li>
          
        
          
            <li>
              <a href="https://oldcamel.run/post/victoriametrics-hui-zong-duo-ge-prometheus-zhi-biao-san-du-qu-istio-zhi-biao/">VictoriaMetrics 汇总多个Prometheus指标（四）读取Istio指标</a>
            </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </div>
  <div class="paper">
    <div class="sidebar-title">
      标签列表
    </div>
    <div class="row">
      
        <a href="https://oldcamel.run/tag/RISUKUMRV/" class="badge warning">
          kubernetes
        </a>
      
        <a href="https://oldcamel.run/tag/AfOZDj8Cpm/" class="badge secondary">
          kafka
        </a>
      
        <a href="https://oldcamel.run/tag/L9nUjvZyjL/" class="badge secondary">
          oracle
        </a>
      
        <a href="https://oldcamel.run/tag/VDLSOs9Sv/" class="badge secondary">
          k8s
        </a>
      
        <a href="https://oldcamel.run/tag/dITV2_NRd/" class="badge secondary">
          VictoriaMetrics
        </a>
      
        <a href="https://oldcamel.run/tag/LXP4Ksl29/" class="badge secondary">
          prometheus
        </a>
      
        <a href="https://oldcamel.run/tag/0BLo6JsC8/" class="badge secondary">
          flowable
        </a>
      
        <a href="https://oldcamel.run/tag/KOvNrkSXn/" class="badge success">
          beam
        </a>
      
        <a href="https://oldcamel.run/tag/xOjaMtgYtD/" class="badge warning">
          clickhouse
        </a>
      
    </div>
  </div>
  <div class="paper">
     | <a class="rss" href="https://oldcamel.run/atom.xml" target="_blank">RSS</a>
  </div>
</div>


    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>

<script type="application/javascript">

AOS.init();

hljs.initHighlightingOnLoad()

</script>




  </body>
</html>
